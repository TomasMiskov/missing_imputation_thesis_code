{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCAR datasets: ['airfoil_MCAR.csv', 'christine_MCAR.csv', 'philippine_MCAR.csv', 'phoneme_MCAR.csv', 'wine_quality_MCAR.csv']\n",
      "MNAR datasets: ['airfoil_MNAR.csv', 'christine_MNAR.csv', 'philippine_MNAR.csv', 'phoneme_MNAR.csv', 'wine_quality_MNAR.csv']\n",
      "Datasets with missing values: ['cirrhosis.csv', 'equity.csv', 'fico.csv', 'support.csv', 'wiki.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "directory = '../processed_data/no_miss'\n",
    "datasets = os.listdir(directory)\n",
    "datasets_MCAR = [dataset for dataset in datasets if dataset[-7] == 'C']\n",
    "datasets_MNAR = [dataset for dataset in datasets if dataset[-7] == 'N']\n",
    "\n",
    "directory = '../processed_data/yes_miss'\n",
    "datasets = os.listdir(directory)\n",
    "\n",
    "print('MCAR datasets:', datasets_MCAR)\n",
    "print('MNAR datasets:', datasets_MNAR)\n",
    "print('Datasets with missing values:', datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def prepareData(dataset_name, SEED):\n",
    "    \n",
    "    if 'MCAR' in dataset_name or 'MNAR' in dataset_name:\n",
    "        data = pd.read_csv(f'../processed_data/no_miss/{dataset_name}')\n",
    "    else:\n",
    "        data = pd.read_csv(f'../processed_data/yes_miss/{dataset_name}')\n",
    "    \n",
    "    y = data.y.values\n",
    "    X = data.drop('y', axis=1).values\n",
    "    n, dim = X.shape\n",
    "\n",
    "    if len(data.y.unique()) == 2:\n",
    "        regression = False\n",
    "    else:\n",
    "        regression = True\n",
    "\n",
    "    # Split the data into training, validation, and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                        random_state=SEED, stratify=y if not regression else None)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, \n",
    "                                                      random_state=SEED, stratify=y_train if not regression else None)\n",
    "    \n",
    "    \n",
    "    # Normalize and scale according to the training set\n",
    "    eps = 1e-6\n",
    "    mean = np.nanmean(X_train, axis=0)\n",
    "    std = np.nanstd(X_train, axis=0) + eps\n",
    "    X_train = (X_train - mean) / std\n",
    "    X_val = (X_val - mean) / std\n",
    "    X_test = (X_test - mean) / std\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test, dim, regression\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "def data2Tensors(X_train, X_val, X_test, y_train, y_val, y_test):\n",
    "    train_batch = int(2**np.ceil(np.log2(X_train.shape[0]//10)))\n",
    "    X_train, X_val, X_test = [torch.tensor(x, dtype=torch.float32) for x in [X_train, X_val, X_test]]\n",
    "    y_train, y_val, y_test = [torch.tensor(y, dtype=torch.float32) for y in [y_train, y_val, y_test]]\n",
    "    \n",
    "    train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=train_batch, shuffle=True)\n",
    "    val_loader, test_loader = [DataLoader(TensorDataset(X, y), batch_size=X.shape[0], shuffle=False) for X, y in [(X_val, y_val), (X_test, y_test)]]\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "from train_utils import getPredictions\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "def appendResults(model, test_loader, device, training_time, regression_flag):\n",
    "    y_pred, y_test = getPredictions(model, test_loader, device)\n",
    "\n",
    "    if regression_flag:\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        return [training_time, mse, mae, r2, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "\n",
    "    else:\n",
    "        y_pred, y_test = getPredictions(model, test_loader, device)\n",
    "        y_pred = ((torch.sigmoid(torch.tensor(y_pred)) >= 0.5) * 1.).cpu().numpy()\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred)\n",
    "        rec = recall_score(y_test, y_pred)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred)\n",
    "        return [training_time, np.nan, np.nan, np.nan, acc, prec, rec, f1, roc_auc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 1, Seed: 1, Model: (Custom Dropout - Regression)\n",
      "\n",
      "Epoch 500, val loss: 13569.1884765625\n",
      "Epoch 1000, val loss: 6349.57666015625\n",
      "Epoch 1500, val loss: 2471.039306640625\n",
      "Epoch 2000, val loss: 543.5783081054688\n",
      "Epoch 2500, val loss: 233.14556884765625\n",
      "Epoch 3000, val loss: 117.56036376953125\n",
      "Epoch 3500, val loss: 59.41341018676758\n",
      "Epoch 4000, val loss: 39.628868103027344\n",
      "Epoch 4500, val loss: 31.80002784729004\n",
      "Epoch 5000, val loss: 29.001121520996094\n",
      "Dataset: 1, Seed: 1, Model: (NeuMiss - Regression)\n",
      "\n",
      "Epoch 500, val loss: 2707.973388671875\n",
      "Epoch 1000, val loss: 1023.2122192382812\n",
      "Epoch 1500, val loss: 229.57289123535156\n",
      "Epoch 2000, val loss: 82.78677368164062\n",
      "Epoch 2500, val loss: 53.61659240722656\n",
      "Epoch 3000, val loss: 41.883968353271484\n",
      "Epoch 3500, val loss: 35.67790222167969\n",
      "Epoch 4000, val loss: 32.16339111328125\n",
      "Epoch 4500, val loss: 30.31755828857422\n",
      "Epoch 5000, val loss: 29.157289505004883\n",
      "\n",
      "Training results: 0.3942 (Dropout) | 0.4670 (NeuMiss)\n",
      "\n",
      "Dataset: 1, Seed: 2, Model: (Custom Dropout - Regression)\n",
      "\n",
      "Epoch 500, val loss: 9774.2744140625\n",
      "Epoch 1000, val loss: 3701.224853515625\n",
      "Epoch 1500, val loss: 1323.735595703125\n",
      "Epoch 2000, val loss: 411.49871826171875\n",
      "Epoch 2500, val loss: 132.425048828125\n",
      "Epoch 3000, val loss: 59.587730407714844\n",
      "Epoch 3500, val loss: 37.73428726196289\n",
      "Epoch 4000, val loss: 30.383092880249023\n",
      "Epoch 4500, val loss: 27.46082878112793\n",
      "Epoch 5000, val loss: 25.839994430541992\n",
      "Dataset: 1, Seed: 2, Model: (NeuMiss - Regression)\n",
      "\n",
      "Epoch 500, val loss: 4472.04150390625\n",
      "Epoch 1000, val loss: 2926.026123046875\n",
      "Epoch 1500, val loss: 1415.6119384765625\n",
      "Epoch 2000, val loss: 1021.1165161132812\n",
      "Epoch 2500, val loss: 737.1979370117188\n",
      "Epoch 3000, val loss: 521.8043212890625\n",
      "Epoch 3500, val loss: 360.5369567871094\n",
      "Epoch 4000, val loss: 238.04713439941406\n",
      "Epoch 4500, val loss: 183.41514587402344\n",
      "Epoch 5000, val loss: 143.1575469970703\n",
      "\n",
      "Training results: 0.3061 (Dropout) | -2.4106 (NeuMiss)\n",
      "\n",
      "Dataset: 1, Seed: 3, Model: (Custom Dropout - Regression)\n",
      "\n",
      "Epoch 500, val loss: 8786.703125\n",
      "Epoch 1000, val loss: 3265.540771484375\n",
      "Epoch 1500, val loss: 775.3206176757812\n",
      "Epoch 2000, val loss: 360.16131591796875\n",
      "Epoch 2500, val loss: 162.45465087890625\n",
      "Epoch 3000, val loss: 65.12318420410156\n",
      "Epoch 3500, val loss: 34.14168930053711\n",
      "Epoch 4000, val loss: 28.281293869018555\n",
      "Epoch 4500, val loss: 26.32298469543457\n",
      "Epoch 5000, val loss: 25.31364631652832\n",
      "Dataset: 1, Seed: 3, Model: (NeuMiss - Regression)\n",
      "\n",
      "Epoch 500, val loss: 5443.69482421875\n",
      "Epoch 1000, val loss: 3413.234130859375\n",
      "Epoch 1500, val loss: 1664.571044921875\n",
      "Epoch 2000, val loss: 968.490478515625\n",
      "Epoch 2500, val loss: 485.8356018066406\n",
      "Epoch 3000, val loss: 292.538330078125\n",
      "Epoch 3500, val loss: 176.51368713378906\n",
      "Epoch 4000, val loss: 106.98983001708984\n",
      "Epoch 4500, val loss: 68.37686920166016\n",
      "Epoch 5000, val loss: 48.201168060302734\n",
      "\n",
      "Training results: 0.3963 (Dropout) | -0.0750 (NeuMiss)\n",
      "\n",
      "Dataset: 1, Seed: 4, Model: (Custom Dropout - Regression)\n",
      "\n",
      "Epoch 500, val loss: 7398.5341796875\n",
      "Epoch 1000, val loss: 2509.748046875\n",
      "Epoch 1500, val loss: 685.5579833984375\n",
      "Epoch 2000, val loss: 253.51817321777344\n",
      "Epoch 2500, val loss: 84.11709594726562\n",
      "Epoch 3000, val loss: 43.4304313659668\n",
      "Epoch 3500, val loss: 32.897911071777344\n",
      "Epoch 4000, val loss: 30.00046730041504\n",
      "Epoch 4500, val loss: 29.151226043701172\n",
      "Epoch 5000, val loss: 28.915868759155273\n",
      "Dataset: 1, Seed: 4, Model: (NeuMiss - Regression)\n",
      "\n",
      "Epoch 500, val loss: 3674.561279296875\n",
      "Epoch 1000, val loss: 1928.247802734375\n",
      "Epoch 1500, val loss: 1110.865966796875\n",
      "Epoch 2000, val loss: 711.8275146484375\n",
      "Epoch 2500, val loss: 442.52532958984375\n",
      "Epoch 3000, val loss: 234.8522186279297\n",
      "Epoch 3500, val loss: 93.06262969970703\n",
      "Epoch 4000, val loss: 34.906410217285156\n",
      "Epoch 4500, val loss: 27.18912696838379\n",
      "Epoch 5000, val loss: 25.781057357788086\n",
      "\n",
      "Training results: 0.4927 (Dropout) | 0.5359 (NeuMiss)\n",
      "\n",
      "Dataset: 1, Seed: 5, Model: (Custom Dropout - Regression)\n",
      "\n",
      "Epoch 500, val loss: 8580.783203125\n",
      "Epoch 1000, val loss: 2753.075927734375\n",
      "Epoch 1500, val loss: 510.7320251464844\n",
      "Epoch 2000, val loss: 193.9131317138672\n",
      "Epoch 2500, val loss: 75.89785766601562\n",
      "Epoch 3000, val loss: 40.389678955078125\n",
      "Epoch 3500, val loss: 30.1319637298584\n",
      "Epoch 4000, val loss: 25.789094924926758\n",
      "Epoch 4500, val loss: 24.213411331176758\n",
      "Epoch 5000, val loss: 23.043540954589844\n",
      "Dataset: 1, Seed: 5, Model: (NeuMiss - Regression)\n",
      "\n",
      "Epoch 500, val loss: 3581.417236328125\n",
      "Epoch 1000, val loss: 1594.2745361328125\n",
      "Epoch 1500, val loss: 860.2724609375\n",
      "Epoch 2000, val loss: 520.1931762695312\n",
      "Epoch 2500, val loss: 328.4060974121094\n",
      "Epoch 3000, val loss: 227.10031127929688\n",
      "Epoch 3500, val loss: 162.01585388183594\n",
      "Epoch 4000, val loss: 116.57101440429688\n",
      "Epoch 4500, val loss: 84.55721282958984\n",
      "Epoch 5000, val loss: 57.11693572998047\n",
      "\n",
      "Training results: 0.5218 (Dropout) | -0.1885 (NeuMiss)\n",
      "\n",
      "Dataset: 2, Seed: 1, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Dataset: 2, Seed: 1, Model: (NeuMiss - Classification)\n",
      "\n",
      "\n",
      "Training results: 0.7039 (Dropout) | 0.7030 (NeuMiss)\n",
      "\n",
      "Dataset: 2, Seed: 2, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Dataset: 2, Seed: 2, Model: (NeuMiss - Classification)\n",
      "\n",
      "\n",
      "Training results: 0.7085 (Dropout) | 0.7039 (NeuMiss)\n",
      "\n",
      "Dataset: 2, Seed: 3, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Dataset: 2, Seed: 3, Model: (NeuMiss - Classification)\n",
      "\n",
      "\n",
      "Training results: 0.7297 (Dropout) | 0.7066 (NeuMiss)\n",
      "\n",
      "Dataset: 2, Seed: 4, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Dataset: 2, Seed: 4, Model: (NeuMiss - Classification)\n",
      "\n",
      "\n",
      "Training results: 0.7205 (Dropout) | 0.6974 (NeuMiss)\n",
      "\n",
      "Dataset: 2, Seed: 5, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Dataset: 2, Seed: 5, Model: (NeuMiss - Classification)\n",
      "\n",
      "\n",
      "Training results: 0.6993 (Dropout) | 0.6910 (NeuMiss)\n",
      "\n",
      "Dataset: 3, Seed: 1, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Dataset: 3, Seed: 1, Model: (NeuMiss - Classification)\n",
      "\n",
      "\n",
      "Training results: 0.6804 (Dropout) | 0.6924 (NeuMiss)\n",
      "\n",
      "Dataset: 3, Seed: 2, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Dataset: 3, Seed: 2, Model: (NeuMiss - Classification)\n",
      "\n",
      "\n",
      "Training results: 0.6873 (Dropout) | 0.6873 (NeuMiss)\n",
      "\n",
      "Dataset: 3, Seed: 3, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Dataset: 3, Seed: 3, Model: (NeuMiss - Classification)\n",
      "\n",
      "\n",
      "Training results: 0.6787 (Dropout) | 0.6692 (NeuMiss)\n",
      "\n",
      "Dataset: 3, Seed: 4, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Dataset: 3, Seed: 4, Model: (NeuMiss - Classification)\n",
      "\n",
      "\n",
      "Training results: 0.7087 (Dropout) | 0.6727 (NeuMiss)\n",
      "\n",
      "Dataset: 3, Seed: 5, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Dataset: 3, Seed: 5, Model: (NeuMiss - Classification)\n",
      "\n",
      "\n",
      "Training results: 0.7035 (Dropout) | 0.6624 (NeuMiss)\n",
      "\n",
      "Dataset: 4, Seed: 1, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Epoch 500, val loss: 0.3739978075027466\n",
      "Epoch 1000, val loss: 0.33456987142562866\n",
      "Epoch 1500, val loss: 0.319506973028183\n",
      "Epoch 2000, val loss: 0.31548309326171875\n",
      "Epoch 2500, val loss: 0.3135911524295807\n",
      "Dataset: 4, Seed: 1, Model: (NeuMiss - Classification)\n",
      "\n",
      "Epoch 500, val loss: 0.34895893931388855\n",
      "Epoch 1000, val loss: 0.3344467282295227\n",
      "Epoch 1500, val loss: 0.32945457100868225\n",
      "Epoch 2000, val loss: 0.32692962884902954\n",
      "\n",
      "Training results: 0.8231 (Dropout) | 0.7911 (NeuMiss)\n",
      "\n",
      "Dataset: 4, Seed: 2, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Epoch 500, val loss: 0.5259212851524353\n",
      "Epoch 1000, val loss: 0.46152257919311523\n",
      "Epoch 1500, val loss: 0.4207497835159302\n",
      "Epoch 2000, val loss: 0.39358600974082947\n",
      "Epoch 2500, val loss: 0.3696134686470032\n",
      "Epoch 3000, val loss: 0.3473447561264038\n",
      "Epoch 3500, val loss: 0.32957953214645386\n",
      "Epoch 4000, val loss: 0.3181239664554596\n",
      "Epoch 4500, val loss: 0.31146907806396484\n",
      "Epoch 5000, val loss: 0.30760708451271057\n",
      "Dataset: 4, Seed: 2, Model: (NeuMiss - Classification)\n",
      "\n",
      "Epoch 500, val loss: 0.3756111264228821\n",
      "Epoch 1000, val loss: 0.33849531412124634\n",
      "Epoch 1500, val loss: 0.3258625268936157\n",
      "Epoch 2000, val loss: 0.32258501648902893\n",
      "Epoch 2500, val loss: 0.31929704546928406\n",
      "\n",
      "Training results: 0.7534 (Dropout) | 0.7851 (NeuMiss)\n",
      "\n",
      "Dataset: 4, Seed: 3, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Epoch 500, val loss: 0.3680688738822937\n",
      "Epoch 1000, val loss: 0.35013601183891296\n",
      "Epoch 1500, val loss: 0.34295201301574707\n",
      "Epoch 2000, val loss: 0.34175053238868713\n",
      "Dataset: 4, Seed: 3, Model: (NeuMiss - Classification)\n",
      "\n",
      "Epoch 500, val loss: 0.40752115845680237\n",
      "Epoch 1000, val loss: 0.3675542175769806\n",
      "Epoch 1500, val loss: 0.35542404651641846\n",
      "Epoch 2000, val loss: 0.34795570373535156\n",
      "\n",
      "Training results: 0.7823 (Dropout) | 0.7618 (NeuMiss)\n",
      "\n",
      "Dataset: 4, Seed: 4, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Epoch 500, val loss: 0.4134904742240906\n",
      "Epoch 1000, val loss: 0.3933827877044678\n",
      "Epoch 1500, val loss: 0.38535431027412415\n",
      "Epoch 2000, val loss: 0.37937891483306885\n",
      "Epoch 2500, val loss: 0.37135976552963257\n",
      "Epoch 3000, val loss: 0.3656180202960968\n",
      "Dataset: 4, Seed: 4, Model: (NeuMiss - Classification)\n",
      "\n",
      "Epoch 500, val loss: 0.44476479291915894\n",
      "Epoch 1000, val loss: 0.3959295153617859\n",
      "Epoch 1500, val loss: 0.37612196803092957\n",
      "Epoch 2000, val loss: 0.3578852713108063\n",
      "Epoch 2500, val loss: 0.3463166356086731\n",
      "Epoch 3000, val loss: 0.3405090272426605\n",
      "Epoch 3500, val loss: 0.33567342162132263\n",
      "Epoch 4000, val loss: 0.33035650849342346\n",
      "\n",
      "Training results: 0.8023 (Dropout) | 0.8036 (NeuMiss)\n",
      "\n",
      "Dataset: 4, Seed: 5, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Epoch 500, val loss: 0.4175044000148773\n",
      "Epoch 1000, val loss: 0.3777469992637634\n",
      "Epoch 1500, val loss: 0.3620626628398895\n",
      "Epoch 2000, val loss: 0.35008886456489563\n",
      "Epoch 2500, val loss: 0.3460761308670044\n",
      "Epoch 3000, val loss: 0.3420301675796509\n",
      "Epoch 3500, val loss: 0.3377353847026825\n",
      "Epoch 4000, val loss: 0.3341448903083801\n",
      "Epoch 4500, val loss: 0.33170944452285767\n",
      "Dataset: 4, Seed: 5, Model: (NeuMiss - Classification)\n",
      "\n",
      "Epoch 500, val loss: 0.38309791684150696\n",
      "Epoch 1000, val loss: 0.3604212701320648\n",
      "Epoch 1500, val loss: 0.3563137650489807\n",
      "Epoch 2000, val loss: 0.35484421253204346\n",
      "Epoch 2500, val loss: 0.35222017765045166\n",
      "\n",
      "Training results: 0.8140 (Dropout) | 0.7705 (NeuMiss)\n",
      "\n",
      "Dataset: 5, Seed: 1, Model: (Custom Dropout - Regression)\n",
      "\n",
      "Epoch 500, val loss: 2.3578579425811768\n",
      "Epoch 1000, val loss: 1.1537073850631714\n",
      "Epoch 1500, val loss: 0.7082698941230774\n",
      "Epoch 2000, val loss: 0.6502406597137451\n",
      "Epoch 2500, val loss: 0.6380679607391357\n",
      "Dataset: 5, Seed: 1, Model: (NeuMiss - Regression)\n",
      "\n",
      "Epoch 500, val loss: 1.518596887588501\n",
      "Epoch 1000, val loss: 0.8313356637954712\n",
      "Epoch 1500, val loss: 0.6569153070449829\n",
      "Epoch 2000, val loss: 0.6189731359481812\n",
      "Epoch 2500, val loss: 0.6059311032295227\n",
      "\n",
      "Training results: 0.2289 (Dropout) | 0.2922 (NeuMiss)\n",
      "\n",
      "Dataset: 5, Seed: 2, Model: (Custom Dropout - Regression)\n",
      "\n",
      "Epoch 500, val loss: 1.6472647190093994\n",
      "Epoch 1000, val loss: 0.7742288708686829\n",
      "Epoch 1500, val loss: 0.6450413465499878\n",
      "Epoch 2000, val loss: 0.6222023367881775\n",
      "Dataset: 5, Seed: 2, Model: (NeuMiss - Regression)\n",
      "\n",
      "Epoch 500, val loss: 1.2494522333145142\n",
      "Epoch 1000, val loss: 0.77916020154953\n",
      "Epoch 1500, val loss: 0.6438148021697998\n",
      "Epoch 2000, val loss: 0.6048058867454529\n",
      "Epoch 2500, val loss: 0.5930438041687012\n",
      "\n",
      "Training results: 0.1874 (Dropout) | 0.2374 (NeuMiss)\n",
      "\n",
      "Dataset: 5, Seed: 3, Model: (Custom Dropout - Regression)\n",
      "\n",
      "Epoch 500, val loss: 2.167775869369507\n",
      "Epoch 1000, val loss: 0.8860084414482117\n",
      "Epoch 1500, val loss: 0.5787782073020935\n",
      "Epoch 2000, val loss: 0.5405957698822021\n",
      "Epoch 2500, val loss: 0.5362444519996643\n",
      "Dataset: 5, Seed: 3, Model: (NeuMiss - Regression)\n",
      "\n",
      "Epoch 500, val loss: 1.4180610179901123\n",
      "Epoch 1000, val loss: 0.7481711506843567\n",
      "Epoch 1500, val loss: 0.578085720539093\n",
      "Epoch 2000, val loss: 0.538258969783783\n",
      "Epoch 2500, val loss: 0.5293552875518799\n",
      "\n",
      "Training results: 0.2511 (Dropout) | 0.2316 (NeuMiss)\n",
      "\n",
      "Dataset: 5, Seed: 4, Model: (Custom Dropout - Regression)\n",
      "\n",
      "Epoch 500, val loss: 2.6233713626861572\n",
      "Epoch 1000, val loss: 1.0796754360198975\n",
      "Epoch 1500, val loss: 0.6466172933578491\n",
      "Epoch 2000, val loss: 0.5988684892654419\n",
      "Dataset: 5, Seed: 4, Model: (NeuMiss - Regression)\n",
      "\n",
      "Epoch 500, val loss: 1.69083833694458\n",
      "Epoch 1000, val loss: 0.866432785987854\n",
      "Epoch 1500, val loss: 0.6402826309204102\n",
      "Epoch 2000, val loss: 0.598906397819519\n",
      "Epoch 2500, val loss: 0.593186616897583\n",
      "Epoch 3000, val loss: 0.5862112045288086\n",
      "\n",
      "Training results: 0.2746 (Dropout) | 0.3129 (NeuMiss)\n",
      "\n",
      "Dataset: 5, Seed: 5, Model: (Custom Dropout - Regression)\n",
      "\n",
      "Epoch 500, val loss: 1.8913283348083496\n",
      "Epoch 1000, val loss: 0.7571162581443787\n",
      "Epoch 1500, val loss: 0.6171990036964417\n",
      "Epoch 2000, val loss: 0.6003202199935913\n",
      "Dataset: 5, Seed: 5, Model: (NeuMiss - Regression)\n",
      "\n",
      "Epoch 500, val loss: 1.3168824911117554\n",
      "Epoch 1000, val loss: 0.7636741399765015\n",
      "Epoch 1500, val loss: 0.6278708577156067\n",
      "Epoch 2000, val loss: 0.587827742099762\n",
      "Epoch 2500, val loss: 0.5712624192237854\n",
      "Epoch 3000, val loss: 0.5636404752731323\n",
      "\n",
      "Training results: 0.2934 (Dropout) | 0.2748 (NeuMiss)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Time\n",
    "import time\n",
    "\n",
    "# Sklearn Metrics\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# MLP\n",
    "from models import CustomDropoutModel, CustomNeuMissMLP\n",
    "from train_utils import train, getPredictions\n",
    "\n",
    "# Evaluation\n",
    "metrics = ['time', 'mse', 'mae', 'r2', 'acc', 'prec', 'rec', 'f1', 'roc_auc']\n",
    "\n",
    "# Experiment\n",
    "seeds = [int(bin(i)[2:]) for i in list(range(5))]\n",
    "results_dropout = np.zeros((len(datasets_MCAR), len(seeds), len(metrics)))\n",
    "results_neumiss = np.zeros((len(datasets_MCAR), len(seeds), len(metrics)))\n",
    "\n",
    "for did, mcar_dataset in enumerate(datasets_MCAR):\n",
    "    for sid, seed in enumerate(seeds):\n",
    "        # Prepare data\n",
    "        X_train, X_val, X_test, y_train, y_val, y_test, dim, regression = prepareData(mcar_dataset, seed)\n",
    "        train_loader, val_loader, test_loader = data2Tensors(X_train, X_val, X_test, y_train, y_val, y_test)\n",
    "        \n",
    "        if regression:\n",
    "            # Fit Custom Dropout Model\n",
    "            print(f'Dataset: {did+1}, Seed: {sid+1}, Model: (Custom Dropout - Regression)\\n')\n",
    "            start_time = time.time()\n",
    "            dropout_model = CustomDropoutModel(input_layer=dim, \n",
    "                                               na_layers=[2**int(np.log2(dim)+1)], \n",
    "                                               model_layers=[2**int(np.log2(dim)+1), 2**int(np.log2(dim))])\n",
    "            epochs = 5000\n",
    "            patience = 100\n",
    "            device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "            \n",
    "            train(model=dropout_model, \n",
    "                  train_loader=train_loader, \n",
    "                  val_loader=val_loader, \n",
    "                  epochs=epochs, \n",
    "                  patience=patience, \n",
    "                  regression_flag=regression, \n",
    "                  device=device, \n",
    "                  seed=seed,\n",
    "                  verbose = True)\n",
    "            end_time = time.time()\n",
    "\n",
    "            training_time = end_time - start_time\n",
    "            results_dropout[did, sid] = appendResults(dropout_model, test_loader, device, training_time, regression)\n",
    "\n",
    "            # Fit NeuMiss Model\n",
    "            print(f'Dataset: {did+1}, Seed: {sid+1}, Model: (NeuMiss - Regression)\\n')\n",
    "            start_time = time.time()\n",
    "            neumiss_model = CustomNeuMissMLP(n_features=dim, \n",
    "                                             neumiss_depth=30,\n",
    "                                             mlp_layers=[2**int(np.log2(dim)+1), 2**int(np.log2(dim))])\n",
    "            epochs = 5000\n",
    "            patience = 100\n",
    "            device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "            \n",
    "            train(model=neumiss_model, \n",
    "                  train_loader=train_loader, \n",
    "                  val_loader=val_loader, \n",
    "                  epochs=epochs, \n",
    "                  patience=patience, \n",
    "                  regression_flag=regression, \n",
    "                  device=device, \n",
    "                  seed=seed,\n",
    "                  verbose = True)\n",
    "            end_time = time.time()\n",
    "\n",
    "            training_time = end_time - start_time\n",
    "            results_neumiss[did, sid] = appendResults(neumiss_model, test_loader, device, training_time, regression)\n",
    "            \n",
    "        else:\n",
    "            # Fit Custom Dropout Model\n",
    "            print(f'Dataset: {did+1}, Seed: {sid+1}, Model: (Custom Dropout - Classification)\\n')\n",
    "            start_time = time.time()\n",
    "            dropout_model = CustomDropoutModel(input_layer=dim, \n",
    "                                               na_layers=[2**int(np.log2(dim)+1)], \n",
    "                                               model_layers=[2**int(np.log2(dim)+1), 2**int(np.log2(dim))])\n",
    "            epochs = 5000\n",
    "            patience = 100\n",
    "            device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "            \n",
    "            train(model=dropout_model, \n",
    "                  train_loader=train_loader, \n",
    "                  val_loader=val_loader, \n",
    "                  epochs=epochs, \n",
    "                  patience=patience, \n",
    "                  regression_flag=regression, \n",
    "                  device=device, \n",
    "                  seed=seed,\n",
    "                  verbose = True)\n",
    "            end_time = time.time()\n",
    "\n",
    "            training_time = end_time - start_time\n",
    "            results_dropout[did, sid] = appendResults(dropout_model, test_loader, device, training_time, regression)\n",
    "\n",
    "            # Fit NeuMiss Model\n",
    "            print(f'Dataset: {did+1}, Seed: {sid+1}, Model: (NeuMiss - Classification)\\n')\n",
    "            start_time = time.time()\n",
    "            neumiss_model = CustomNeuMissMLP(n_features=dim, \n",
    "                                             neumiss_depth=30,\n",
    "                                             mlp_layers=[2**int(np.log2(dim)+1), 2**int(np.log2(dim))])\n",
    "            epochs = 5000\n",
    "            patience = 100\n",
    "            device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "            \n",
    "            train(model=neumiss_model, \n",
    "                  train_loader=train_loader, \n",
    "                  val_loader=val_loader, \n",
    "                  epochs=epochs, \n",
    "                  patience=patience, \n",
    "                  regression_flag=regression, \n",
    "                  device=device, \n",
    "                  seed=seed,\n",
    "                  verbose = True)\n",
    "            end_time = time.time()\n",
    "\n",
    "            training_time = end_time - start_time\n",
    "            results_neumiss[did, sid] = appendResults(neumiss_model, test_loader, device, training_time, regression)\n",
    "\n",
    "        print(f'\\nTraining results: {results_dropout[did, sid][3] if regression else results_dropout[did, sid][-1]:.4f} (Dropout) | {results_neumiss[did, sid][3] if regression else results_neumiss[did, sid][-1]:.4f} (NeuMiss)\\n')\n",
    "        np.save('../results/raw/results_dropout_MCAR.npy', results_dropout)\n",
    "        np.save('../results/raw/results_neumiss_MCAR.npy', results_neumiss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 1, Seed: 1, Model: (Custom Dropout - Regression)\n",
      "\n",
      "Epoch 500, val loss: 13515.3828125\n",
      "Epoch 1000, val loss: 7335.3916015625\n",
      "Epoch 1500, val loss: 4007.19677734375\n",
      "Epoch 2000, val loss: 1268.1922607421875\n",
      "Epoch 2500, val loss: 432.17218017578125\n",
      "Epoch 3000, val loss: 143.4412078857422\n",
      "Epoch 3500, val loss: 78.02128601074219\n",
      "Epoch 4000, val loss: 46.11606216430664\n",
      "Epoch 4500, val loss: 33.57711410522461\n",
      "Epoch 5000, val loss: 26.761905670166016\n",
      "Dataset: 1, Seed: 1, Model: (NeuMiss - Regression)\n",
      "\n",
      "Epoch 500, val loss: 1144.7779541015625\n",
      "Epoch 1000, val loss: 619.6669311523438\n",
      "Epoch 1500, val loss: 340.102783203125\n",
      "Epoch 2000, val loss: 190.78880310058594\n",
      "Epoch 2500, val loss: 107.05058288574219\n",
      "Epoch 3000, val loss: 63.77729797363281\n",
      "Epoch 3500, val loss: 45.013710021972656\n",
      "Epoch 4000, val loss: 37.328758239746094\n",
      "Epoch 4500, val loss: 31.453142166137695\n",
      "Epoch 5000, val loss: 27.65372085571289\n",
      "\n",
      "Training results: 0.4511 (Dropout) | 0.5571 (NeuMiss)\n",
      "\n",
      "Dataset: 1, Seed: 2, Model: (Custom Dropout - Regression)\n",
      "\n",
      "Epoch 500, val loss: 7513.9755859375\n",
      "Epoch 1000, val loss: 3021.249267578125\n",
      "Epoch 1500, val loss: 904.7022094726562\n",
      "Epoch 2000, val loss: 338.7189025878906\n",
      "Epoch 2500, val loss: 139.04405212402344\n",
      "Epoch 3000, val loss: 63.00442886352539\n",
      "Epoch 3500, val loss: 37.35020446777344\n",
      "Epoch 4000, val loss: 26.937517166137695\n",
      "Epoch 4500, val loss: 22.755050659179688\n",
      "Epoch 5000, val loss: 20.77341079711914\n",
      "Dataset: 1, Seed: 2, Model: (NeuMiss - Regression)\n",
      "\n",
      "Epoch 500, val loss: 3037.34375\n",
      "Epoch 1000, val loss: 1779.6424560546875\n",
      "Epoch 1500, val loss: 1160.2142333984375\n",
      "Epoch 2000, val loss: 779.8547973632812\n",
      "Epoch 2500, val loss: 511.85430908203125\n",
      "Epoch 3000, val loss: 333.1617126464844\n",
      "Epoch 3500, val loss: 256.15338134765625\n",
      "Epoch 4000, val loss: 209.12353515625\n",
      "Epoch 4500, val loss: 175.7756805419922\n",
      "Epoch 5000, val loss: 149.80914306640625\n",
      "\n",
      "Training results: 0.4201 (Dropout) | -1.9946 (NeuMiss)\n",
      "\n",
      "Dataset: 1, Seed: 3, Model: (Custom Dropout - Regression)\n",
      "\n",
      "Epoch 500, val loss: 7000.3974609375\n",
      "Epoch 1000, val loss: 2868.067626953125\n",
      "Epoch 1500, val loss: 835.0635986328125\n",
      "Epoch 2000, val loss: 252.34193420410156\n",
      "Epoch 2500, val loss: 97.19271850585938\n",
      "Epoch 3000, val loss: 42.77055740356445\n",
      "Epoch 3500, val loss: 29.347537994384766\n",
      "Epoch 4000, val loss: 24.357446670532227\n",
      "Epoch 4500, val loss: 22.44314956665039\n",
      "Epoch 5000, val loss: 21.608863830566406\n",
      "Dataset: 1, Seed: 3, Model: (NeuMiss - Regression)\n",
      "\n",
      "Epoch 500, val loss: 9147.2099609375\n",
      "Epoch 1000, val loss: 2020.8179931640625\n",
      "Epoch 1500, val loss: 1641.3035888671875\n",
      "Epoch 2000, val loss: 1264.9517822265625\n",
      "Epoch 2500, val loss: 773.6336059570312\n",
      "Epoch 3000, val loss: 439.3681335449219\n",
      "Epoch 3500, val loss: 290.0707092285156\n",
      "Epoch 4000, val loss: 213.89498901367188\n",
      "Epoch 4500, val loss: 160.71534729003906\n",
      "Epoch 5000, val loss: 125.5328598022461\n",
      "\n",
      "Training results: 0.5661 (Dropout) | -1.2362 (NeuMiss)\n",
      "\n",
      "Dataset: 1, Seed: 4, Model: (Custom Dropout - Regression)\n",
      "\n",
      "Epoch 500, val loss: 5891.630859375\n",
      "Epoch 1000, val loss: 2146.929931640625\n",
      "Epoch 1500, val loss: 698.6320190429688\n",
      "Epoch 2000, val loss: 160.68597412109375\n",
      "Epoch 2500, val loss: 54.81941223144531\n",
      "Epoch 3000, val loss: 30.90213394165039\n",
      "Epoch 3500, val loss: 23.469825744628906\n",
      "Epoch 4000, val loss: 21.163349151611328\n",
      "Epoch 4500, val loss: 20.36179542541504\n",
      "Epoch 5000, val loss: 19.655622482299805\n",
      "Dataset: 1, Seed: 4, Model: (NeuMiss - Regression)\n",
      "\n",
      "Epoch 500, val loss: 2980.853271484375\n",
      "Epoch 1000, val loss: 1789.2967529296875\n",
      "Epoch 1500, val loss: 1145.9722900390625\n",
      "Epoch 2000, val loss: 742.290771484375\n",
      "Epoch 2500, val loss: 476.50164794921875\n",
      "Epoch 3000, val loss: 323.8148498535156\n",
      "Epoch 3500, val loss: 221.97047424316406\n",
      "Epoch 4000, val loss: 163.19415283203125\n",
      "Epoch 4500, val loss: 124.23320770263672\n",
      "Epoch 5000, val loss: 94.83895874023438\n",
      "\n",
      "Training results: 0.5402 (Dropout) | -1.4525 (NeuMiss)\n",
      "\n",
      "Dataset: 1, Seed: 5, Model: (Custom Dropout - Regression)\n",
      "\n",
      "Epoch 500, val loss: 6588.89501953125\n",
      "Epoch 1000, val loss: 1538.643798828125\n",
      "Epoch 1500, val loss: 454.42755126953125\n",
      "Epoch 2000, val loss: 142.11325073242188\n",
      "Epoch 2500, val loss: 58.025238037109375\n",
      "Epoch 3000, val loss: 30.53948211669922\n",
      "Epoch 3500, val loss: 22.55303382873535\n",
      "Epoch 4000, val loss: 19.418893814086914\n",
      "Epoch 4500, val loss: 18.178850173950195\n",
      "Epoch 5000, val loss: 17.19133949279785\n",
      "Dataset: 1, Seed: 5, Model: (NeuMiss - Regression)\n",
      "\n",
      "Epoch 500, val loss: 2421.32275390625\n",
      "Epoch 1000, val loss: 1902.136474609375\n",
      "Epoch 1500, val loss: 1586.1025390625\n",
      "Epoch 2000, val loss: 829.7122802734375\n",
      "Epoch 2500, val loss: 375.8794860839844\n",
      "Epoch 3000, val loss: 262.5706787109375\n",
      "Epoch 3500, val loss: 194.8098907470703\n",
      "Epoch 4000, val loss: 150.8911895751953\n",
      "Epoch 4500, val loss: 121.0357894897461\n",
      "Epoch 5000, val loss: 98.16356658935547\n",
      "\n",
      "Training results: 0.5870 (Dropout) | -1.3202 (NeuMiss)\n",
      "\n",
      "Dataset: 2, Seed: 1, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Dataset: 2, Seed: 1, Model: (NeuMiss - Classification)\n",
      "\n",
      "\n",
      "Training results: 0.7159 (Dropout) | 0.6725 (NeuMiss)\n",
      "\n",
      "Dataset: 2, Seed: 2, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Dataset: 2, Seed: 2, Model: (NeuMiss - Classification)\n",
      "\n",
      "\n",
      "Training results: 0.6937 (Dropout) | 0.6734 (NeuMiss)\n",
      "\n",
      "Dataset: 2, Seed: 3, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Dataset: 2, Seed: 3, Model: (NeuMiss - Classification)\n",
      "\n",
      "\n",
      "Training results: 0.7371 (Dropout) | 0.6910 (NeuMiss)\n",
      "\n",
      "Dataset: 2, Seed: 4, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Dataset: 2, Seed: 4, Model: (NeuMiss - Classification)\n",
      "\n",
      "\n",
      "Training results: 0.7315 (Dropout) | 0.6891 (NeuMiss)\n",
      "\n",
      "Dataset: 2, Seed: 5, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Dataset: 2, Seed: 5, Model: (NeuMiss - Classification)\n",
      "\n",
      "\n",
      "Training results: 0.7103 (Dropout) | 0.6679 (NeuMiss)\n",
      "\n",
      "Dataset: 3, Seed: 1, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Dataset: 3, Seed: 1, Model: (NeuMiss - Classification)\n",
      "\n",
      "\n",
      "Training results: 0.6941 (Dropout) | 0.6975 (NeuMiss)\n",
      "\n",
      "Dataset: 3, Seed: 2, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Dataset: 3, Seed: 2, Model: (NeuMiss - Classification)\n",
      "\n",
      "\n",
      "Training results: 0.6701 (Dropout) | 0.6855 (NeuMiss)\n",
      "\n",
      "Dataset: 3, Seed: 3, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Dataset: 3, Seed: 3, Model: (NeuMiss - Classification)\n",
      "\n",
      "\n",
      "Training results: 0.6864 (Dropout) | 0.6821 (NeuMiss)\n",
      "\n",
      "Dataset: 3, Seed: 4, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Dataset: 3, Seed: 4, Model: (NeuMiss - Classification)\n",
      "\n",
      "\n",
      "Training results: 0.6967 (Dropout) | 0.6890 (NeuMiss)\n",
      "\n",
      "Dataset: 3, Seed: 5, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Dataset: 3, Seed: 5, Model: (NeuMiss - Classification)\n",
      "\n",
      "\n",
      "Training results: 0.7095 (Dropout) | 0.6915 (NeuMiss)\n",
      "\n",
      "Dataset: 4, Seed: 1, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Epoch 500, val loss: 0.389925092458725\n",
      "Epoch 1000, val loss: 0.3405248522758484\n",
      "Epoch 1500, val loss: 0.31696227192878723\n",
      "Epoch 2000, val loss: 0.3077200651168823\n",
      "Epoch 2500, val loss: 0.3043687045574188\n",
      "Epoch 3000, val loss: 0.3023711144924164\n",
      "Epoch 3500, val loss: 0.30121564865112305\n",
      "Epoch 4000, val loss: 0.30067089200019836\n",
      "Epoch 4500, val loss: 0.2994205355644226\n",
      "Epoch 5000, val loss: 0.2979387938976288\n",
      "Dataset: 4, Seed: 1, Model: (NeuMiss - Classification)\n",
      "\n",
      "Epoch 500, val loss: 0.3727058172225952\n",
      "Epoch 1000, val loss: 0.35858866572380066\n",
      "Epoch 1500, val loss: 0.3496817648410797\n",
      "Epoch 2000, val loss: 0.34355849027633667\n",
      "Epoch 2500, val loss: 0.338472455739975\n",
      "Epoch 3000, val loss: 0.3341841697692871\n",
      "Epoch 3500, val loss: 0.3305610418319702\n",
      "Epoch 4000, val loss: 0.32745906710624695\n",
      "Epoch 4500, val loss: 0.32513687014579773\n",
      "Epoch 5000, val loss: 0.3210258483886719\n",
      "\n",
      "Training results: 0.8336 (Dropout) | 0.8199 (NeuMiss)\n",
      "\n",
      "Dataset: 4, Seed: 2, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Epoch 500, val loss: 0.3749406635761261\n",
      "Epoch 1000, val loss: 0.328293114900589\n",
      "Epoch 1500, val loss: 0.3004576861858368\n",
      "Epoch 2000, val loss: 0.2872668206691742\n",
      "Epoch 2500, val loss: 0.28090500831604004\n",
      "Epoch 3000, val loss: 0.2767629027366638\n",
      "Epoch 3500, val loss: 0.2734375596046448\n",
      "Epoch 4000, val loss: 0.271304726600647\n",
      "Epoch 4500, val loss: 0.2700944244861603\n",
      "Epoch 5000, val loss: 0.26934149861335754\n",
      "Dataset: 4, Seed: 2, Model: (NeuMiss - Classification)\n",
      "\n",
      "Epoch 500, val loss: 0.36405107378959656\n",
      "Epoch 1000, val loss: 0.325015664100647\n",
      "Epoch 1500, val loss: 0.30647173523902893\n",
      "Epoch 2000, val loss: 0.30018165707588196\n",
      "Epoch 2500, val loss: 0.2950928807258606\n",
      "Epoch 3000, val loss: 0.2924553155899048\n",
      "Epoch 3500, val loss: 0.290652334690094\n",
      "\n",
      "Training results: 0.8212 (Dropout) | 0.8178 (NeuMiss)\n",
      "\n",
      "Dataset: 4, Seed: 3, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Epoch 500, val loss: 0.41460636258125305\n",
      "Epoch 1000, val loss: 0.3855355679988861\n",
      "Epoch 1500, val loss: 0.3567771911621094\n",
      "Epoch 2000, val loss: 0.33838778734207153\n",
      "Epoch 2500, val loss: 0.3302403390407562\n",
      "Epoch 3000, val loss: 0.32516342401504517\n",
      "Epoch 3500, val loss: 0.32203730940818787\n",
      "Epoch 4000, val loss: 0.3201712965965271\n",
      "Epoch 4500, val loss: 0.31982699036598206\n",
      "Dataset: 4, Seed: 3, Model: (NeuMiss - Classification)\n",
      "\n",
      "Epoch 500, val loss: 0.3894660174846649\n",
      "Epoch 1000, val loss: 0.36688530445098877\n",
      "Epoch 1500, val loss: 0.3378165066242218\n",
      "Epoch 2000, val loss: 0.3272823691368103\n",
      "Epoch 2500, val loss: 0.32350578904151917\n",
      "Epoch 3000, val loss: 0.32097843289375305\n",
      "Epoch 3500, val loss: 0.3188308775424957\n",
      "\n",
      "Training results: 0.8057 (Dropout) | 0.8003 (NeuMiss)\n",
      "\n",
      "Dataset: 4, Seed: 4, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Epoch 500, val loss: 0.37191224098205566\n",
      "Epoch 1000, val loss: 0.3349771499633789\n",
      "Epoch 1500, val loss: 0.3200691044330597\n",
      "Epoch 2000, val loss: 0.311969518661499\n",
      "Epoch 2500, val loss: 0.3025864064693451\n",
      "Epoch 3000, val loss: 0.2985665500164032\n",
      "Epoch 3500, val loss: 0.29652392864227295\n",
      "Epoch 4000, val loss: 0.2952757775783539\n",
      "Epoch 4500, val loss: 0.29424920678138733\n",
      "Epoch 5000, val loss: 0.2937358021736145\n",
      "Dataset: 4, Seed: 4, Model: (NeuMiss - Classification)\n",
      "\n",
      "Epoch 500, val loss: 0.34716281294822693\n",
      "Epoch 1000, val loss: 0.323927104473114\n",
      "Epoch 1500, val loss: 0.31727686524391174\n",
      "Epoch 2000, val loss: 0.31198206543922424\n",
      "Epoch 2500, val loss: 0.3076786398887634\n",
      "Epoch 3000, val loss: 0.3044070899486542\n",
      "Epoch 3500, val loss: 0.30160588026046753\n",
      "Epoch 4000, val loss: 0.299466073513031\n",
      "Epoch 4500, val loss: 0.29783204197883606\n",
      "Epoch 5000, val loss: 0.2964165508747101\n",
      "\n",
      "Training results: 0.8170 (Dropout) | 0.7870 (NeuMiss)\n",
      "\n",
      "Dataset: 4, Seed: 5, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Epoch 500, val loss: 0.4121374487876892\n",
      "Epoch 1000, val loss: 0.36663976311683655\n",
      "Epoch 1500, val loss: 0.3340992331504822\n",
      "Epoch 2000, val loss: 0.3200443685054779\n",
      "Epoch 2500, val loss: 0.311018705368042\n",
      "Epoch 3000, val loss: 0.30732259154319763\n",
      "Epoch 3500, val loss: 0.3040001392364502\n",
      "Epoch 4000, val loss: 0.30076318979263306\n",
      "Epoch 4500, val loss: 0.2988472282886505\n",
      "Epoch 5000, val loss: 0.2966550290584564\n",
      "Dataset: 4, Seed: 5, Model: (NeuMiss - Classification)\n",
      "\n",
      "Epoch 500, val loss: 0.3780025541782379\n",
      "Epoch 1000, val loss: 0.351534903049469\n",
      "Epoch 1500, val loss: 0.3377281725406647\n",
      "Epoch 2000, val loss: 0.3324141800403595\n",
      "Epoch 2500, val loss: 0.3283739686012268\n",
      "Epoch 3000, val loss: 0.32443875074386597\n",
      "Epoch 3500, val loss: 0.32172203063964844\n",
      "Epoch 4000, val loss: 0.3189271092414856\n",
      "Epoch 4500, val loss: 0.317598819732666\n",
      "Epoch 5000, val loss: 0.31605806946754456\n",
      "\n",
      "Training results: 0.8180 (Dropout) | 0.8024 (NeuMiss)\n",
      "\n",
      "Dataset: 5, Seed: 1, Model: (Custom Dropout - Regression)\n",
      "\n",
      "Epoch 500, val loss: 1.4908287525177002\n",
      "Epoch 1000, val loss: 0.821046769618988\n",
      "Epoch 1500, val loss: 0.6523607969284058\n",
      "Epoch 2000, val loss: 0.612622082233429\n",
      "Epoch 2500, val loss: 0.6025838851928711\n",
      "Epoch 3000, val loss: 0.5983635187149048\n",
      "Dataset: 5, Seed: 1, Model: (NeuMiss - Regression)\n",
      "\n",
      "Epoch 500, val loss: 0.8963479995727539\n",
      "Epoch 1000, val loss: 0.6685678362846375\n",
      "Epoch 1500, val loss: 0.6224828362464905\n",
      "Epoch 2000, val loss: 0.6115770936012268\n",
      "Epoch 2500, val loss: 0.6066418886184692\n",
      "\n",
      "Training results: 0.3001 (Dropout) | 0.0553 (NeuMiss)\n",
      "\n",
      "Dataset: 5, Seed: 2, Model: (Custom Dropout - Regression)\n",
      "\n",
      "Epoch 500, val loss: 1.4682104587554932\n",
      "Epoch 1000, val loss: 0.7685585618019104\n",
      "Epoch 1500, val loss: 0.6446174383163452\n",
      "Epoch 2000, val loss: 0.6105528473854065\n",
      "Epoch 2500, val loss: 0.5992879271507263\n",
      "Epoch 3000, val loss: 0.5924409627914429\n",
      "Dataset: 5, Seed: 2, Model: (NeuMiss - Regression)\n",
      "\n",
      "Epoch 500, val loss: 1.033945918083191\n",
      "Epoch 1000, val loss: 0.710432767868042\n",
      "Epoch 1500, val loss: 0.6092728972434998\n",
      "Epoch 2000, val loss: 0.5782514214515686\n",
      "Epoch 2500, val loss: 0.5628138184547424\n",
      "\n",
      "Training results: 0.2607 (Dropout) | 0.2438 (NeuMiss)\n",
      "\n",
      "Dataset: 5, Seed: 3, Model: (Custom Dropout - Regression)\n",
      "\n",
      "Epoch 500, val loss: 1.5699491500854492\n",
      "Epoch 1000, val loss: 0.7349817156791687\n",
      "Epoch 1500, val loss: 0.546046793460846\n",
      "Epoch 2000, val loss: 0.5148746371269226\n",
      "Epoch 2500, val loss: 0.5046724677085876\n",
      "Dataset: 5, Seed: 3, Model: (NeuMiss - Regression)\n",
      "\n",
      "Epoch 500, val loss: 0.8372091054916382\n",
      "Epoch 1000, val loss: 0.6222385168075562\n",
      "Epoch 1500, val loss: 0.53982013463974\n",
      "Epoch 2000, val loss: 0.5132507085800171\n",
      "Epoch 2500, val loss: 0.5049688220024109\n",
      "\n",
      "Training results: 0.3024 (Dropout) | 0.3114 (NeuMiss)\n",
      "\n",
      "Dataset: 5, Seed: 4, Model: (Custom Dropout - Regression)\n",
      "\n",
      "Epoch 500, val loss: 1.6618144512176514\n",
      "Epoch 1000, val loss: 0.7995560169219971\n",
      "Epoch 1500, val loss: 0.6057203412055969\n",
      "Epoch 2000, val loss: 0.5705793499946594\n",
      "Epoch 2500, val loss: 0.55720454454422\n",
      "Epoch 3000, val loss: 0.5512152910232544\n",
      "Dataset: 5, Seed: 4, Model: (NeuMiss - Regression)\n",
      "\n",
      "Epoch 500, val loss: 1.1194772720336914\n",
      "Epoch 1000, val loss: 0.6337697505950928\n",
      "Epoch 1500, val loss: 0.5627046823501587\n",
      "Epoch 2000, val loss: 0.5479871034622192\n",
      "Epoch 2500, val loss: 0.5399690866470337\n",
      "Epoch 3000, val loss: 0.5326340794563293\n",
      "Epoch 3500, val loss: 0.5273855328559875\n",
      "\n",
      "Training results: 0.3051 (Dropout) | 0.3334 (NeuMiss)\n",
      "\n",
      "Dataset: 5, Seed: 5, Model: (Custom Dropout - Regression)\n",
      "\n",
      "Epoch 500, val loss: 1.7024587392807007\n",
      "Epoch 1000, val loss: 0.7643297910690308\n",
      "Epoch 1500, val loss: 0.6002644300460815\n",
      "Epoch 2000, val loss: 0.5666036605834961\n",
      "Epoch 2500, val loss: 0.5536651611328125\n",
      "Epoch 3000, val loss: 0.5464687943458557\n",
      "Dataset: 5, Seed: 5, Model: (NeuMiss - Regression)\n",
      "\n",
      "Epoch 500, val loss: 0.9077851176261902\n",
      "Epoch 1000, val loss: 0.664909839630127\n",
      "Epoch 1500, val loss: 0.6023723483085632\n",
      "Epoch 2000, val loss: 0.5813441872596741\n",
      "Epoch 2500, val loss: 0.5741243958473206\n",
      "Epoch 3000, val loss: 0.5667437314987183\n",
      "\n",
      "Training results: 0.3183 (Dropout) | 0.2947 (NeuMiss)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Time\n",
    "import time\n",
    "\n",
    "# Sklearn Metrics\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# MLP\n",
    "from models import CustomDropoutModel, CustomNeuMissMLP\n",
    "from train_utils import train\n",
    "\n",
    "# Evaluation\n",
    "metrics = ['time', 'mse', 'mae', 'r2', 'acc', 'prec', 'rec', 'f1', 'roc_auc']\n",
    "\n",
    "# Experiment\n",
    "seeds = [int(bin(i)[2:]) for i in list(range(5))]\n",
    "results_dropout = np.zeros((len(datasets_MNAR), len(seeds), len(metrics)))\n",
    "results_neumiss = np.zeros((len(datasets_MNAR), len(seeds), len(metrics)))\n",
    "\n",
    "for did, mnar_dataset in enumerate(datasets_MNAR):\n",
    "    for sid, seed in enumerate(seeds):\n",
    "        # Prepare data\n",
    "        X_train, X_val, X_test, y_train, y_val, y_test, dim, regression = prepareData(mnar_dataset, seed)\n",
    "        train_loader, val_loader, test_loader = data2Tensors(X_train, X_val, X_test, y_train, y_val, y_test)\n",
    "        \n",
    "        if regression:\n",
    "            # Fit Custom Dropout Model\n",
    "            print(f'Dataset: {did+1}, Seed: {sid+1}, Model: (Custom Dropout - Regression)\\n')\n",
    "            start_time = time.time()\n",
    "            dropout_model = CustomDropoutModel(input_layer=dim, \n",
    "                                               na_layers=[2**int(np.log2(dim)+1)], \n",
    "                                               model_layers=[2**int(np.log2(dim)+1), 2**int(np.log2(dim))])\n",
    "            epochs = 5000\n",
    "            patience = 100\n",
    "            device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "            \n",
    "            train(model=dropout_model, \n",
    "                  train_loader=train_loader, \n",
    "                  val_loader=val_loader, \n",
    "                  epochs=epochs, \n",
    "                  patience=patience, \n",
    "                  regression_flag=regression, \n",
    "                  device=device, \n",
    "                  seed=seed,\n",
    "                  verbose = True)\n",
    "            end_time = time.time()\n",
    "\n",
    "            training_time = end_time - start_time\n",
    "            results_dropout[did, sid] = appendResults(dropout_model, test_loader, device, training_time, regression)\n",
    "\n",
    "            # Fit NeuMiss Model\n",
    "            print(f'Dataset: {did+1}, Seed: {sid+1}, Model: (NeuMiss - Regression)\\n')\n",
    "            start_time = time.time()\n",
    "            neumiss_model = CustomNeuMissMLP(n_features=dim, \n",
    "                                             neumiss_depth=30,\n",
    "                                             mlp_layers=[2**int(np.log2(dim)+1), 2**int(np.log2(dim))])\n",
    "            epochs = 5000\n",
    "            patience = 100\n",
    "            device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "            \n",
    "            train(model=neumiss_model, \n",
    "                  train_loader=train_loader, \n",
    "                  val_loader=val_loader, \n",
    "                  epochs=epochs, \n",
    "                  patience=patience, \n",
    "                  regression_flag=regression, \n",
    "                  device=device, \n",
    "                  seed=seed,\n",
    "                  verbose = True)\n",
    "            end_time = time.time()\n",
    "\n",
    "            training_time = end_time - start_time\n",
    "            results_neumiss[did, sid] = appendResults(neumiss_model, test_loader, device, training_time, regression)\n",
    "            \n",
    "        else:\n",
    "            # Fit Custom Dropout Model\n",
    "            print(f'Dataset: {did+1}, Seed: {sid+1}, Model: (Custom Dropout - Classification)\\n')\n",
    "            start_time = time.time()\n",
    "            dropout_model = CustomDropoutModel(input_layer=dim, \n",
    "                                               na_layers=[2**int(np.log2(dim)+1)], \n",
    "                                               model_layers=[2**int(np.log2(dim)+1), 2**int(np.log2(dim))])\n",
    "            epochs = 5000\n",
    "            patience = 100\n",
    "            device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "            \n",
    "            train(model=dropout_model, \n",
    "                  train_loader=train_loader, \n",
    "                  val_loader=val_loader, \n",
    "                  epochs=epochs, \n",
    "                  patience=patience, \n",
    "                  regression_flag=regression, \n",
    "                  device=device, \n",
    "                  seed=seed,\n",
    "                  verbose = True)\n",
    "            end_time = time.time()\n",
    "\n",
    "            training_time = end_time - start_time\n",
    "            results_dropout[did, sid] = appendResults(dropout_model, test_loader, device, training_time, regression)\n",
    "\n",
    "            # Fit NeuMiss Model\n",
    "            print(f'Dataset: {did+1}, Seed: {sid+1}, Model: (NeuMiss - Classification)\\n')\n",
    "            start_time = time.time()\n",
    "            neumiss_model = CustomNeuMissMLP(n_features=dim, \n",
    "                                             neumiss_depth=30,\n",
    "                                             mlp_layers=[2**int(np.log2(dim)+1), 2**int(np.log2(dim))])\n",
    "            epochs = 5000\n",
    "            patience = 100\n",
    "            device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "            \n",
    "            train(model=neumiss_model, \n",
    "                  train_loader=train_loader, \n",
    "                  val_loader=val_loader, \n",
    "                  epochs=epochs, \n",
    "                  patience=patience, \n",
    "                  regression_flag=regression, \n",
    "                  device=device, \n",
    "                  seed=seed,\n",
    "                  verbose = True)\n",
    "            end_time = time.time()\n",
    "\n",
    "            training_time = end_time - start_time\n",
    "            results_neumiss[did, sid] = appendResults(neumiss_model, test_loader, device, training_time, regression)\n",
    "\n",
    "        print(f'\\nTraining results: {results_dropout[did, sid][3] if regression else results_dropout[did, sid][-1]:.4f} (Dropout) | {results_neumiss[did, sid][3] if regression else results_neumiss[did, sid][-1]:.4f} (NeuMiss)\\n')\n",
    "        np.save('../results/raw/results_dropout_MNAR.npy', results_dropout)\n",
    "        np.save('../results/raw/results_neumiss_MNAR.npy', results_neumiss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REAL MISSINGNESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 1, Seed: 1, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Epoch 500, val loss: 0.5226673483848572\n",
      "Dataset: 1, Seed: 1, Model: (NeuMiss - Classification)\n",
      "\n",
      "\n",
      "Training results: 0.7300 (Dropout) | 0.7171 (NeuMiss)\n",
      "\n",
      "Dataset: 1, Seed: 2, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Epoch 500, val loss: 0.5339129567146301\n",
      "Dataset: 1, Seed: 2, Model: (NeuMiss - Classification)\n",
      "\n",
      "Epoch 500, val loss: 0.5232256650924683\n",
      "\n",
      "Training results: 0.6786 (Dropout) | 0.6863 (NeuMiss)\n",
      "\n",
      "Dataset: 1, Seed: 3, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Dataset: 1, Seed: 3, Model: (NeuMiss - Classification)\n",
      "\n",
      "\n",
      "Training results: 0.7301 (Dropout) | 0.7070 (NeuMiss)\n",
      "\n",
      "Dataset: 1, Seed: 4, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Dataset: 1, Seed: 4, Model: (NeuMiss - Classification)\n",
      "\n",
      "\n",
      "Training results: 0.7198 (Dropout) | 0.7455 (NeuMiss)\n",
      "\n",
      "Dataset: 1, Seed: 5, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Epoch 500, val loss: 0.5456133484840393\n",
      "Dataset: 1, Seed: 5, Model: (NeuMiss - Classification)\n",
      "\n",
      "\n",
      "Training results: 0.7404 (Dropout) | 0.7790 (NeuMiss)\n",
      "\n",
      "Dataset: 2, Seed: 1, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Epoch 500, val loss: 0.4621354043483734\n",
      "Dataset: 2, Seed: 1, Model: (NeuMiss - Classification)\n",
      "\n",
      "Epoch 500, val loss: 0.4577536880970001\n",
      "Epoch 1000, val loss: 0.4270135164260864\n",
      "\n",
      "Training results: 0.8562 (Dropout) | 0.8399 (NeuMiss)\n",
      "\n",
      "Dataset: 2, Seed: 2, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Epoch 500, val loss: 0.46466511487960815\n",
      "Dataset: 2, Seed: 2, Model: (NeuMiss - Classification)\n",
      "\n",
      "Epoch 500, val loss: 0.44855961203575134\n",
      "Epoch 1000, val loss: 0.4393298923969269\n",
      "\n",
      "Training results: 0.8115 (Dropout) | 0.8483 (NeuMiss)\n",
      "\n",
      "Dataset: 2, Seed: 3, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Epoch 500, val loss: 0.49910926818847656\n",
      "Dataset: 2, Seed: 3, Model: (NeuMiss - Classification)\n",
      "\n",
      "Epoch 500, val loss: 0.5265769958496094\n",
      "Epoch 1000, val loss: 0.4977652132511139\n",
      "\n",
      "Training results: 0.8288 (Dropout) | 0.8577 (NeuMiss)\n",
      "\n",
      "Dataset: 2, Seed: 4, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Epoch 500, val loss: 0.45768770575523376\n",
      "Dataset: 2, Seed: 4, Model: (NeuMiss - Classification)\n",
      "\n",
      "Epoch 500, val loss: 0.4782417118549347\n",
      "Epoch 1000, val loss: 0.43276527523994446\n",
      "\n",
      "Training results: 0.8577 (Dropout) | 0.8483 (NeuMiss)\n",
      "\n",
      "Dataset: 2, Seed: 5, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Epoch 500, val loss: 0.42146697640419006\n",
      "Epoch 1000, val loss: 0.3890351951122284\n",
      "Dataset: 2, Seed: 5, Model: (NeuMiss - Classification)\n",
      "\n",
      "Epoch 500, val loss: 0.3936668932437897\n",
      "Epoch 1000, val loss: 0.37668129801750183\n",
      "\n",
      "Training results: 0.8320 (Dropout) | 0.8320 (NeuMiss)\n",
      "\n",
      "Dataset: 3, Seed: 1, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Dataset: 3, Seed: 1, Model: (NeuMiss - Classification)\n",
      "\n",
      "\n",
      "Training results: 0.7288 (Dropout) | 0.7260 (NeuMiss)\n",
      "\n",
      "Dataset: 3, Seed: 2, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Dataset: 3, Seed: 2, Model: (NeuMiss - Classification)\n",
      "\n",
      "\n",
      "Training results: 0.7288 (Dropout) | 0.7402 (NeuMiss)\n",
      "\n",
      "Dataset: 3, Seed: 3, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Dataset: 3, Seed: 3, Model: (NeuMiss - Classification)\n",
      "\n",
      "\n",
      "Training results: 0.7171 (Dropout) | 0.7288 (NeuMiss)\n",
      "\n",
      "Dataset: 3, Seed: 4, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Dataset: 3, Seed: 4, Model: (NeuMiss - Classification)\n",
      "\n",
      "\n",
      "Training results: 0.7298 (Dropout) | 0.7395 (NeuMiss)\n",
      "\n",
      "Dataset: 3, Seed: 5, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Dataset: 3, Seed: 5, Model: (NeuMiss - Classification)\n",
      "\n",
      "\n",
      "Training results: 0.7318 (Dropout) | 0.7358 (NeuMiss)\n",
      "\n",
      "Dataset: 4, Seed: 1, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Dataset: 4, Seed: 1, Model: (NeuMiss - Classification)\n",
      "\n",
      "\n",
      "Training results: 0.8305 (Dropout) | 0.8192 (NeuMiss)\n",
      "\n",
      "Dataset: 4, Seed: 2, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Dataset: 4, Seed: 2, Model: (NeuMiss - Classification)\n",
      "\n",
      "\n",
      "Training results: 0.7926 (Dropout) | 0.7929 (NeuMiss)\n",
      "\n",
      "Dataset: 4, Seed: 3, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Dataset: 4, Seed: 3, Model: (NeuMiss - Classification)\n",
      "\n",
      "\n",
      "Training results: 0.8229 (Dropout) | 0.8758 (NeuMiss)\n",
      "\n",
      "Dataset: 4, Seed: 4, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Dataset: 4, Seed: 4, Model: (NeuMiss - Classification)\n",
      "\n",
      "\n",
      "Training results: 0.8645 (Dropout) | 0.8720 (NeuMiss)\n",
      "\n",
      "Dataset: 4, Seed: 5, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Dataset: 4, Seed: 5, Model: (NeuMiss - Classification)\n",
      "\n",
      "\n",
      "Training results: 0.8566 (Dropout) | 0.8868 (NeuMiss)\n",
      "\n",
      "Dataset: 5, Seed: 1, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Dataset: 5, Seed: 1, Model: (NeuMiss - Classification)\n",
      "\n",
      "\n",
      "Training results: 0.7837 (Dropout) | 0.7939 (NeuMiss)\n",
      "\n",
      "Dataset: 5, Seed: 2, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Dataset: 5, Seed: 2, Model: (NeuMiss - Classification)\n",
      "\n",
      "\n",
      "Training results: 0.8196 (Dropout) | 0.8385 (NeuMiss)\n",
      "\n",
      "Dataset: 5, Seed: 3, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Dataset: 5, Seed: 3, Model: (NeuMiss - Classification)\n",
      "\n",
      "\n",
      "Training results: 0.8030 (Dropout) | 0.7621 (NeuMiss)\n",
      "\n",
      "Dataset: 5, Seed: 4, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Dataset: 5, Seed: 4, Model: (NeuMiss - Classification)\n",
      "\n",
      "\n",
      "Training results: 0.7965 (Dropout) | 0.8295 (NeuMiss)\n",
      "\n",
      "Dataset: 5, Seed: 5, Model: (Custom Dropout - Classification)\n",
      "\n",
      "Dataset: 5, Seed: 5, Model: (NeuMiss - Classification)\n",
      "\n",
      "\n",
      "Training results: 0.8006 (Dropout) | 0.8146 (NeuMiss)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Time\n",
    "import time\n",
    "\n",
    "# MLP\n",
    "from models import CustomDropoutModel, CustomNeuMissMLP\n",
    "from train_utils import train\n",
    "\n",
    "# Evaluation\n",
    "metrics = ['time', 'mse', 'mae', 'r2', 'acc', 'prec', 'rec', 'f1', 'roc_auc']\n",
    "\n",
    "# Experiment\n",
    "seeds = [int(bin(i)[2:]) for i in list(range(5))]\n",
    "results_dropout = np.zeros((len(datasets), len(seeds), len(metrics)))\n",
    "results_neumiss = np.zeros((len(datasets), len(seeds), len(metrics)))\n",
    "\n",
    "for did, dataset in enumerate(datasets):\n",
    "    for sid, seed in enumerate(seeds):\n",
    "        # Prepare data\n",
    "        X_train, X_val, X_test, y_train, y_val, y_test, dim, regression = prepareData(dataset, seed)\n",
    "        train_loader, val_loader, test_loader = data2Tensors(X_train, X_val, X_test, y_train, y_val, y_test)\n",
    "        \n",
    "        if regression:\n",
    "            # Fit Custom Dropout Model\n",
    "            print(f'Dataset: {did+1}, Seed: {sid+1}, Model: (Custom Dropout - Regression)\\n')\n",
    "            start_time = time.time()\n",
    "            dropout_model = CustomDropoutModel(input_layer=dim, \n",
    "                                               na_layers=[2**int(np.log2(dim)+1)], \n",
    "                                               model_layers=[2**int(np.log2(dim)+1), 2**int(np.log2(dim))])\n",
    "            epochs = 5000\n",
    "            patience = 100\n",
    "            device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "            \n",
    "            train(model=dropout_model, \n",
    "                  train_loader=train_loader, \n",
    "                  val_loader=val_loader, \n",
    "                  epochs=epochs, \n",
    "                  patience=patience, \n",
    "                  regression_flag=regression, \n",
    "                  device=device, \n",
    "                  seed=seed,\n",
    "                  verbose = True)\n",
    "            end_time = time.time()\n",
    "\n",
    "            training_time = end_time - start_time\n",
    "            results_dropout[did, sid] = appendResults(dropout_model, test_loader, device, training_time, regression)\n",
    "\n",
    "            # Fit NeuMiss Model\n",
    "            print(f'Dataset: {did+1}, Seed: {sid+1}, Model: (NeuMiss - Regression)\\n')\n",
    "            start_time = time.time()\n",
    "            neumiss_model = CustomNeuMissMLP(n_features=dim, \n",
    "                                             neumiss_depth=30,\n",
    "                                             mlp_layers=[2**int(np.log2(dim)+1), 2**int(np.log2(dim))])\n",
    "            epochs = 5000\n",
    "            patience = 100\n",
    "            device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "            \n",
    "            train(model=neumiss_model, \n",
    "                  train_loader=train_loader, \n",
    "                  val_loader=val_loader, \n",
    "                  epochs=epochs, \n",
    "                  patience=patience, \n",
    "                  regression_flag=regression, \n",
    "                  device=device, \n",
    "                  seed=seed,\n",
    "                  verbose = True)\n",
    "            end_time = time.time()\n",
    "\n",
    "            training_time = end_time - start_time\n",
    "            results_neumiss[did, sid] = appendResults(neumiss_model, test_loader, device, training_time, regression)\n",
    "            \n",
    "        else:\n",
    "            # Fit Custom Dropout Model\n",
    "            print(f'Dataset: {did+1}, Seed: {sid+1}, Model: (Custom Dropout - Classification)\\n')\n",
    "            start_time = time.time()\n",
    "            dropout_model = CustomDropoutModel(input_layer=dim, \n",
    "                                               na_layers=[2**int(np.log2(dim)+1)], \n",
    "                                               model_layers=[2**int(np.log2(dim)+1), 2**int(np.log2(dim))])\n",
    "            epochs = 5000\n",
    "            patience = 100\n",
    "            device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "            \n",
    "            train(model=dropout_model, \n",
    "                  train_loader=train_loader, \n",
    "                  val_loader=val_loader, \n",
    "                  epochs=epochs, \n",
    "                  patience=patience, \n",
    "                  regression_flag=regression, \n",
    "                  device=device, \n",
    "                  seed=seed,\n",
    "                  verbose = True)\n",
    "            end_time = time.time()\n",
    "\n",
    "            training_time = end_time - start_time\n",
    "            results_dropout[did, sid] = appendResults(dropout_model, test_loader, device, training_time, regression)\n",
    "\n",
    "            # Fit NeuMiss Model\n",
    "            print(f'Dataset: {did+1}, Seed: {sid+1}, Model: (NeuMiss - Classification)\\n')\n",
    "            start_time = time.time()\n",
    "            neumiss_model = CustomNeuMissMLP(n_features=dim, \n",
    "                                             neumiss_depth=30,\n",
    "                                             mlp_layers=[2**int(np.log2(dim)+1), 2**int(np.log2(dim))])\n",
    "            epochs = 5000\n",
    "            patience = 100\n",
    "            device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "            \n",
    "            train(model=neumiss_model, \n",
    "                  train_loader=train_loader, \n",
    "                  val_loader=val_loader, \n",
    "                  epochs=epochs, \n",
    "                  patience=patience, \n",
    "                  regression_flag=regression, \n",
    "                  device=device, \n",
    "                  seed=seed,\n",
    "                  verbose = True)\n",
    "            end_time = time.time()\n",
    "\n",
    "            training_time = end_time - start_time\n",
    "            results_neumiss[did, sid] = appendResults(neumiss_model, test_loader, device, training_time, regression)\n",
    "\n",
    "        print(f'\\nTraining results: {results_dropout[did, sid][3] if regression else results_dropout[did, sid][-1]:.4f} (Dropout) | {results_neumiss[did, sid][3] if regression else results_neumiss[did, sid][-1]:.4f} (NeuMiss)\\n')\n",
    "        np.save('../results/raw/results_dropout_real.npy', results_dropout)\n",
    "        np.save('../results/raw/results_neumiss_real.npy', results_neumiss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
