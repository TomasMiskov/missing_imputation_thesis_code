{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCAR datasets: ['airfoil_MCAR.csv', 'christine_MCAR.csv', 'philippine_MCAR.csv', 'phoneme_MCAR.csv', 'wine_quality_MCAR.csv']\n",
      "MNAR datasets: ['airfoil_MNAR.csv', 'christine_MNAR.csv', 'philippine_MNAR.csv', 'phoneme_MNAR.csv', 'wine_quality_MNAR.csv']\n",
      "Datasets with missing values: ['cirrhosis.csv', 'equity.csv', 'fico.csv', 'support.csv', 'wiki.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "directory = '../processed_data/no_miss'\n",
    "datasets = os.listdir(directory)\n",
    "datasets_MCAR = [dataset for dataset in datasets if dataset[-7] == 'C']\n",
    "datasets_MNAR = [dataset for dataset in datasets if dataset[-7] == 'N']\n",
    "\n",
    "directory = '../processed_data/yes_miss'\n",
    "datasets = os.listdir(directory)\n",
    "\n",
    "print('MCAR datasets:', datasets_MCAR)\n",
    "print('MNAR datasets:', datasets_MNAR)\n",
    "print('Datasets with missing values:', datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def prepareDataWithNans(dataset_name, SEED):\n",
    "    data = pd.read_csv(f'../processed_data/no_miss/{dataset_name}')\n",
    "    y = data.y.values\n",
    "    X = data.drop('y', axis=1).values\n",
    "    n, dim = X.shape\n",
    "\n",
    "    if len(data.y.unique()) == 2:\n",
    "        regression = False\n",
    "    else:\n",
    "        regression = True\n",
    "\n",
    "    # Split the data into training, validation, and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                        random_state=SEED, stratify=y if not regression else None)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, \n",
    "                                                      random_state=SEED, stratify=y_train if not regression else None)\n",
    "       \n",
    "    # Normalize and scale according to the training set\n",
    "    eps = 1e-6\n",
    "    mean = np.nanmean(X_train, axis=0)\n",
    "    std = np.nanstd(X_train, axis=0) + eps\n",
    "    X_train = (X_train - mean) / std\n",
    "    X_val = (X_val - mean) / std\n",
    "    X_test = (X_test - mean) / std\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test, dim, regression\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "def data2Tensors(X_train, X_val, X_test, y_train, y_val, y_test):\n",
    "    train_batch = int(2**np.ceil(np.log2(X_train.shape[0]//10)))\n",
    "    X_train, X_val, X_test = [torch.tensor(x, dtype=torch.float32) for x in [X_train, X_val, X_test]]\n",
    "    y_train, y_val, y_test = [torch.tensor(y, dtype=torch.float32) for y in [y_train, y_val, y_test]]\n",
    "    \n",
    "    train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=train_batch, shuffle=True)\n",
    "    val_loader, test_loader = [DataLoader(TensorDataset(X, y), batch_size=X.shape[0], shuffle=False) for X, y in [(X_val, y_val), (X_test, y_test)]]\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 1, Seed: 1 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.4255 (RF)\n",
      "\n",
      "Dataset: 1, Seed: 2 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.2336 (RF)\n",
      "\n",
      "Dataset: 1, Seed: 3 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.2120 (RF)\n",
      "\n",
      "Dataset: 1, Seed: 4 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.4365 (RF)\n",
      "\n",
      "Dataset: 1, Seed: 5 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.2675 (RF)\n",
      "\n",
      "Dataset: 2, Seed: 1 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.7205 (RF)\n",
      "\n",
      "Dataset: 2, Seed: 2 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.6956 (RF)\n",
      "\n",
      "Dataset: 2, Seed: 3 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.7214 (RF)\n",
      "\n",
      "Dataset: 2, Seed: 4 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.7168 (RF)\n",
      "\n",
      "Dataset: 2, Seed: 5 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.7048 (RF)\n",
      "\n",
      "Dataset: 3, Seed: 1 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.7008 (RF)\n",
      "\n",
      "Dataset: 3, Seed: 2 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.6994 (RF)\n",
      "\n",
      "Dataset: 3, Seed: 3 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.6942 (RF)\n",
      "\n",
      "Dataset: 3, Seed: 4 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.6934 (RF)\n",
      "\n",
      "Dataset: 3, Seed: 5 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.7025 (RF)\n",
      "\n",
      "Dataset: 4, Seed: 1 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.7064 (RF)\n",
      "\n",
      "Dataset: 4, Seed: 2 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.7101 (RF)\n",
      "\n",
      "Dataset: 4, Seed: 3 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.7461 (RF)\n",
      "\n",
      "Dataset: 4, Seed: 4 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.6960 (RF)\n",
      "\n",
      "Dataset: 4, Seed: 5 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.7198 (RF)\n",
      "\n",
      "Dataset: 5, Seed: 1 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.2157 (RF)\n",
      "\n",
      "Dataset: 5, Seed: 2 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.2054 (RF)\n",
      "\n",
      "Dataset: 5, Seed: 3 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.2008 (RF)\n",
      "\n",
      "Dataset: 5, Seed: 4 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.2326 (RF)\n",
      "\n",
      "Dataset: 5, Seed: 5 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.2240 (RF)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Time\n",
    "import time\n",
    "\n",
    "# Random Forest\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Evaluation\n",
    "metrics = ['time', 'mse', 'mae', 'r2', 'acc', 'prec', 'rec', 'f1', 'roc_auc']\n",
    "\n",
    "# Experiment\n",
    "seeds = [int(bin(i)[2:]) for i in list(range(5))]\n",
    "results_lgbm_forest = np.zeros((len(datasets_MCAR), len(seeds), len(metrics)))\n",
    "\n",
    "for did, mcar_dataset in enumerate(datasets_MCAR):\n",
    "    for sid, seed in enumerate(seeds):\n",
    "        # Verbose\n",
    "        print(f'Dataset: {did+1}, Seed: {sid+1} STARTING TRAINING\\n')\n",
    "\n",
    "        # Prepare data\n",
    "        X_train, X_val, X_test, y_train, y_val, y_test, dim, regression = prepareDataWithNans(mcar_dataset, seed)\n",
    "        train_loader, val_loader, test_loader = data2Tensors(X_train, X_val, X_test, y_train, y_val, y_test)\n",
    "        \n",
    "        if regression:\n",
    "            # Fit Random Forest\n",
    "            start_time = time.time()\n",
    "            model = lgb.LGBMRegressor(boosting_type='rf',\n",
    "                          max_depth=4,\n",
    "                          n_estimators=1000,\n",
    "                          min_data_in_leaf=5,\n",
    "                          feature_fraction=(dim**0.5)/dim,\n",
    "                          random_state=seed,\n",
    "                          verbosity=-1)\n",
    "            model.fit(X_train, y_train)\n",
    "            end_time = time.time()\n",
    "            \n",
    "            y_pred = model.predict(X_test)\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            mae = mean_absolute_error(y_test, y_pred)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            training_time = end_time - start_time\n",
    "            results_lgbm_forest[did, sid] = [training_time, mse, mae, r2, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "            \n",
    "        else:\n",
    "            # Fit Random Forest\n",
    "            start_time = time.time()\n",
    "            model = lgb.LGBMClassifier(boosting_type='rf',\n",
    "                          max_depth=4,\n",
    "                          n_estimators=500,\n",
    "                          min_data_in_leaf=5,\n",
    "                          feature_fraction=(dim**0.5)/dim,\n",
    "                          random_state=seed,\n",
    "                          verbosity=-1)\n",
    "            model.fit(X_train, y_train)\n",
    "            end_time = time.time()\n",
    "            \n",
    "            y_pred = model.predict(X_test)\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "            prec = precision_score(y_test, y_pred)\n",
    "            rec = recall_score(y_test, y_pred)\n",
    "            roc_auc = roc_auc_score(y_test, y_pred)\n",
    "            training_time = end_time - start_time\n",
    "            results_lgbm_forest[did, sid] = [training_time, np.nan, np.nan, np.nan, acc, prec, rec, f1, roc_auc]\n",
    "\n",
    "        print(f'\\nTraining results: {results_lgbm_forest[did, sid][3] if regression else results_lgbm_forest[did, sid][-1]:.4f} (RF)\\n')\n",
    "        np.save('../results/raw/results_lgbm_MCAR.npy', results_lgbm_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 1, Seed: 1 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.3708 (RF)\n",
      "\n",
      "Dataset: 1, Seed: 2 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.2486 (RF)\n",
      "\n",
      "Dataset: 1, Seed: 3 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.2185 (RF)\n",
      "\n",
      "Dataset: 1, Seed: 4 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.3602 (RF)\n",
      "\n",
      "Dataset: 1, Seed: 5 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.2570 (RF)\n",
      "\n",
      "Dataset: 2, Seed: 1 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.7186 (RF)\n",
      "\n",
      "Dataset: 2, Seed: 2 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.6919 (RF)\n",
      "\n",
      "Dataset: 2, Seed: 3 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.7196 (RF)\n",
      "\n",
      "Dataset: 2, Seed: 4 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.7196 (RF)\n",
      "\n",
      "Dataset: 2, Seed: 5 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.7113 (RF)\n",
      "\n",
      "Dataset: 3, Seed: 1 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.7060 (RF)\n",
      "\n",
      "Dataset: 3, Seed: 2 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.7053 (RF)\n",
      "\n",
      "Dataset: 3, Seed: 3 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.6993 (RF)\n",
      "\n",
      "Dataset: 3, Seed: 4 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.7079 (RF)\n",
      "\n",
      "Dataset: 3, Seed: 5 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.7060 (RF)\n",
      "\n",
      "Dataset: 4, Seed: 1 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.7610 (RF)\n",
      "\n",
      "Dataset: 4, Seed: 2 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.7275 (RF)\n",
      "\n",
      "Dataset: 4, Seed: 3 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.7513 (RF)\n",
      "\n",
      "Dataset: 4, Seed: 4 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.7111 (RF)\n",
      "\n",
      "Dataset: 4, Seed: 5 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.7492 (RF)\n",
      "\n",
      "Dataset: 5, Seed: 1 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.2311 (RF)\n",
      "\n",
      "Dataset: 5, Seed: 2 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.2245 (RF)\n",
      "\n",
      "Dataset: 5, Seed: 3 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.2190 (RF)\n",
      "\n",
      "Dataset: 5, Seed: 4 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.2417 (RF)\n",
      "\n",
      "Dataset: 5, Seed: 5 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.2388 (RF)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Time\n",
    "import time\n",
    "\n",
    "# Random Forest\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Evaluation\n",
    "metrics = ['time', 'mse', 'mae', 'r2', 'acc', 'prec', 'rec', 'f1', 'roc_auc']\n",
    "\n",
    "# Experiment\n",
    "seeds = [int(bin(i)[2:]) for i in list(range(5))]\n",
    "results_lgbm_forest = np.zeros((len(datasets_MNAR), len(seeds), len(metrics)))\n",
    "\n",
    "for did, mnar_dataset in enumerate(datasets_MNAR):\n",
    "    for sid, seed in enumerate(seeds):\n",
    "        # Verbose\n",
    "        print(f'Dataset: {did+1}, Seed: {sid+1} STARTING TRAINING\\n')\n",
    "\n",
    "        # Prepare data\n",
    "        X_train, X_val, X_test, y_train, y_val, y_test, dim, regression = prepareDataWithNans(mnar_dataset, seed)\n",
    "        train_loader, val_loader, test_loader = data2Tensors(X_train, X_val, X_test, y_train, y_val, y_test)\n",
    "        \n",
    "        if regression:\n",
    "            # Fit Random Forest\n",
    "            start_time = time.time()\n",
    "            model = lgb.LGBMRegressor(boosting_type='rf',\n",
    "                          max_depth=4,\n",
    "                          n_estimators=1000,\n",
    "                          min_data_in_leaf=5,\n",
    "                          feature_fraction=(dim**0.5)/dim,\n",
    "                          random_state=seed,\n",
    "                          verbosity=-1)\n",
    "            model.fit(X_train, y_train)\n",
    "            end_time = time.time()\n",
    "            \n",
    "            y_pred = model.predict(X_test)\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            mae = mean_absolute_error(y_test, y_pred)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            training_time = end_time - start_time\n",
    "            results_lgbm_forest[did, sid] = [training_time, mse, mae, r2, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "            \n",
    "        else:\n",
    "            # Fit Random Forest\n",
    "            start_time = time.time()\n",
    "            model = lgb.LGBMClassifier(boosting_type='rf',\n",
    "                          max_depth=4,\n",
    "                          n_estimators=500,\n",
    "                          min_data_in_leaf=5,\n",
    "                          feature_fraction=(dim**0.5)/dim,\n",
    "                          random_state=seed,\n",
    "                          verbosity=-1)\n",
    "            model.fit(X_train, y_train)\n",
    "            end_time = time.time()\n",
    "            \n",
    "            y_pred = model.predict(X_test)\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "            prec = precision_score(y_test, y_pred)\n",
    "            rec = recall_score(y_test, y_pred)\n",
    "            roc_auc = roc_auc_score(y_test, y_pred)\n",
    "            training_time = end_time - start_time\n",
    "            results_lgbm_forest[did, sid] = [training_time, np.nan, np.nan, np.nan, acc, prec, rec, f1, roc_auc]\n",
    "\n",
    "        print(f'\\nTraining results: {results_lgbm_forest[did, sid][3] if regression else results_lgbm_forest[did, sid][-1]:.4f} (RF)\\n')\n",
    "        np.save('../results/raw/results_lgbm_MNAR.npy', results_lgbm_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 1, Seed: 1 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.7377 (RF)\n",
      "\n",
      "Dataset: 1, Seed: 2 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.6990 (RF)\n",
      "\n",
      "Dataset: 1, Seed: 3 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.7274 (RF)\n",
      "\n",
      "Dataset: 1, Seed: 4 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.7480 (RF)\n",
      "\n",
      "Dataset: 1, Seed: 5 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.7660 (RF)\n",
      "\n",
      "Dataset: 2, Seed: 1 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.5767 (RF)\n",
      "\n",
      "Dataset: 2, Seed: 2 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.5793 (RF)\n",
      "\n",
      "Dataset: 2, Seed: 3 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.5972 (RF)\n",
      "\n",
      "Dataset: 2, Seed: 4 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.5735 (RF)\n",
      "\n",
      "Dataset: 2, Seed: 5 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.5798 (RF)\n",
      "\n",
      "Dataset: 3, Seed: 1 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.7203 (RF)\n",
      "\n",
      "Dataset: 3, Seed: 2 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.7196 (RF)\n",
      "\n",
      "Dataset: 3, Seed: 3 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.7310 (RF)\n",
      "\n",
      "Dataset: 3, Seed: 4 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.7380 (RF)\n",
      "\n",
      "Dataset: 3, Seed: 5 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.7308 (RF)\n",
      "\n",
      "Dataset: 4, Seed: 1 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.5645 (RF)\n",
      "\n",
      "Dataset: 4, Seed: 2 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.5833 (RF)\n",
      "\n",
      "Dataset: 4, Seed: 3 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.5873 (RF)\n",
      "\n",
      "Dataset: 4, Seed: 4 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.6402 (RF)\n",
      "\n",
      "Dataset: 4, Seed: 5 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.5720 (RF)\n",
      "\n",
      "Dataset: 5, Seed: 1 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.7668 (RF)\n",
      "\n",
      "Dataset: 5, Seed: 2 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.7618 (RF)\n",
      "\n",
      "Dataset: 5, Seed: 3 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.7274 (RF)\n",
      "\n",
      "Dataset: 5, Seed: 4 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.8140 (RF)\n",
      "\n",
      "Dataset: 5, Seed: 5 STARTING TRAINING\n",
      "\n",
      "\n",
      "Training results: 0.7709 (RF)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def prepareDataWithNans(dataset_name, SEED):\n",
    "    data = pd.read_csv(f'../processed_data/yes_miss/{dataset_name}')\n",
    "    y = data.y.values\n",
    "    X = data.drop('y', axis=1).values\n",
    "    n, dim = X.shape\n",
    "\n",
    "    if len(data.y.unique()) == 2:\n",
    "        regression = False\n",
    "    else:\n",
    "        regression = True\n",
    "\n",
    "    # Split the data into training, validation, and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                        random_state=SEED, stratify=y if not regression else None)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, \n",
    "                                                      random_state=SEED, stratify=y_train if not regression else None)\n",
    "       \n",
    "    # Normalize and scale according to the training set\n",
    "    eps = 1e-6\n",
    "    mean = np.nanmean(X_train, axis=0)\n",
    "    std = np.nanstd(X_train, axis=0) + eps\n",
    "    X_train = (X_train - mean) / std\n",
    "    X_val = (X_val - mean) / std\n",
    "    X_test = (X_test - mean) / std\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test, dim, regression\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "def data2Tensors(X_train, X_val, X_test, y_train, y_val, y_test):\n",
    "    train_batch = int(2**np.ceil(np.log2(X_train.shape[0]//10)))\n",
    "    X_train, X_val, X_test = [torch.tensor(x, dtype=torch.float32) for x in [X_train, X_val, X_test]]\n",
    "    y_train, y_val, y_test = [torch.tensor(y, dtype=torch.float32) for y in [y_train, y_val, y_test]]\n",
    "    \n",
    "    train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=train_batch, shuffle=True)\n",
    "    val_loader, test_loader = [DataLoader(TensorDataset(X, y), batch_size=X.shape[0], shuffle=False) for X, y in [(X_val, y_val), (X_test, y_test)]]\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "#-----------------------------------------------\n",
    "\n",
    "# Time\n",
    "import time\n",
    "\n",
    "# Random Forest\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Evaluation\n",
    "metrics = ['time', 'mse', 'mae', 'r2', 'acc', 'prec', 'rec', 'f1', 'roc_auc']\n",
    "\n",
    "# Experiment\n",
    "seeds = [int(bin(i)[2:]) for i in list(range(5))]\n",
    "results_lgbm_forest = np.zeros((len(datasets), len(seeds), len(metrics)))\n",
    "\n",
    "for did, dataset in enumerate(datasets):\n",
    "    for sid, seed in enumerate(seeds):\n",
    "        # Verbose\n",
    "        print(f'Dataset: {did+1}, Seed: {sid+1} STARTING TRAINING\\n')\n",
    "\n",
    "        # Prepare data\n",
    "        X_train, X_val, X_test, y_train, y_val, y_test, dim, regression = prepareDataWithNans(dataset, seed)\n",
    "        train_loader, val_loader, test_loader = data2Tensors(X_train, X_val, X_test, y_train, y_val, y_test)\n",
    "        \n",
    "        if regression:\n",
    "            # Fit Random Forest\n",
    "            start_time = time.time()\n",
    "            model = lgb.LGBMRegressor(boosting_type='rf',\n",
    "                          max_depth=4,\n",
    "                          n_estimators=1000,\n",
    "                          min_data_in_leaf=5,\n",
    "                          feature_fraction=(dim**0.5)/dim,\n",
    "                          random_state=seed,\n",
    "                          verbosity=-1)\n",
    "            model.fit(X_train, y_train)\n",
    "            end_time = time.time()\n",
    "            \n",
    "            y_pred = model.predict(X_test)\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            mae = mean_absolute_error(y_test, y_pred)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            training_time = end_time - start_time\n",
    "            results_lgbm_forest[did, sid] = [training_time, mse, mae, r2, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "            \n",
    "        else:\n",
    "            # Fit Random Forest\n",
    "            start_time = time.time()\n",
    "            model = lgb.LGBMClassifier(boosting_type='rf',\n",
    "                          max_depth=4,\n",
    "                          n_estimators=500,\n",
    "                          min_data_in_leaf=5,\n",
    "                          feature_fraction=(dim**0.5)/dim,\n",
    "                          random_state=seed,\n",
    "                          verbosity=-1)\n",
    "            model.fit(X_train, y_train)\n",
    "            end_time = time.time()\n",
    "            \n",
    "            y_pred = model.predict(X_test)\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "            prec = precision_score(y_test, y_pred)\n",
    "            rec = recall_score(y_test, y_pred)\n",
    "            roc_auc = roc_auc_score(y_test, y_pred)\n",
    "            training_time = end_time - start_time\n",
    "            results_lgbm_forest[did, sid] = [training_time, np.nan, np.nan, np.nan, acc, prec, rec, f1, roc_auc]\n",
    "\n",
    "        print(f'\\nTraining results: {results_lgbm_forest[did, sid][3] if regression else results_lgbm_forest[did, sid][-1]:.4f} (RF)\\n')\n",
    "        np.save('../results/raw/results_lgbm_real.npy', results_lgbm_forest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
