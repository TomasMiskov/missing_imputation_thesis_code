{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNumMissingPatterns(X):\n",
    "    mask = X.isnull().values\n",
    "    decimal_arr = []\n",
    "    for row in mask:\n",
    "        binary_str = ''.join(['1' if val else '0' for val in row])\n",
    "        decimal_num = int(binary_str, 2)\n",
    "        decimal_arr.append(decimal_num)\n",
    "    \n",
    "    decimal_arr = set(decimal_arr)\n",
    "    if 0 in decimal_arr:\n",
    "        return len(decimal_arr) - 1\n",
    "    else:\n",
    "        return len(decimal_arr) \n",
    "    \n",
    "def cat2Dummies(df, cat_cols):\n",
    "    df = pd.get_dummies(df, columns=cat_cols, dummy_na=True, drop_first = True,dtype=np.float64)\n",
    "    return df\n",
    "\n",
    "def dropColumns(df, cols):\n",
    "    df = df.drop(columns=cols)\n",
    "    return df\n",
    "\n",
    "def dropUninformative(df):\n",
    "    df = df.loc[:, df.std() > 0]\n",
    "    return df\n",
    "\n",
    "def printMissingness(df):\n",
    "    print(f'Percent missing: {df.isna().sum().sum()/df.size:.2%}')\n",
    "    print(f'Percent of observations with at least one missing feature: {df.isna().any(axis=1).sum()/df.shape[0]:.2%}')\n",
    "    print(f'Number of unique missing patterns: {getNumMissingPatterns(df)} out of {2**df.shape[1]:,} possible patterns.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R-DATASETS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chile dataset\n",
    "- source: [CRAN](https://rdrr.io/cran/carData/man/Chile.html)\n",
    "- data about voting intentions of Chileans in 1988 elections\n",
    "- multi-class target of Yes, No, Undecided and Abstain transformed to YES vs. rest classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent missing: 0.29%\n",
      "Percent of observations with at least one missing feature: 3.63%\n",
      "Number of unique missing patterns: 4 out of 8,192 possible patterns.\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "chile = pd.read_csv('datasets\\chile.csv')\n",
    "\n",
    "# drop rows with missing target\n",
    "chile.dropna(subset=['vote'], inplace=True)\n",
    "\n",
    "# process target to binary classification YES vs. REST\n",
    "y = chile['vote']\n",
    "y = y.apply(lambda x: 1.0 if x == 'Y' else 0.0)\n",
    "\n",
    "# process categorical features\n",
    "chile.drop(columns=['rownames', 'vote'], inplace=True)\n",
    "cat_cols = ['region', 'sex', 'education']\n",
    "chile = cat2Dummies(chile, cat_cols)\n",
    "chile = chile.astype(np.float64)\n",
    "\n",
    "# drop non-informative features\n",
    "chile = dropUninformative(chile)\n",
    "\n",
    "# append target and save to csv\n",
    "chile['y'] = y\n",
    "chile.to_csv('processed_data\\chile.csv', index=False)\n",
    "\n",
    "# print missingness information\n",
    "printMissingness(chile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schooling\n",
    "- source: [Ecdat](https://rdrr.io/cran/Ecdat/man/Schooling.html)\n",
    "- data from 1976 about wages and schooling of young men in US\n",
    "- target is log wage, features are about the individual's education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent missing: 1.00%\n",
      "Percent of observations with at least one missing feature: 32.23%\n",
      "Number of unique missing patterns: 3 out of 8,589,934,592 possible patterns.\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "schooling = pd.read_csv('datasets\\schooling.csv')\n",
    "\n",
    "# process target\n",
    "y = schooling['lwage76']\n",
    "\n",
    "# process categorical features\n",
    "drop_cols = ['rownames', 'wage76', 'lwage76']\n",
    "schooling = dropColumns(schooling, drop_cols)\n",
    "\n",
    "cat_cols = schooling.select_dtypes(include=['object']).columns\n",
    "schooling = cat2Dummies(schooling, cat_cols)\n",
    "schooling = schooling.astype(np.float64)\n",
    "\n",
    "# drop non-informative features\n",
    "schooling = dropUninformative(schooling)\n",
    "\n",
    "# append target and save to csv\n",
    "schooling['y'] = y\n",
    "schooling.to_csv('processed_data\\schooling.csv', index=False)\n",
    "\n",
    "# print missingness information\n",
    "printMissingness(schooling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schooling 2\n",
    "- source: [Ecdat](https://rdrr.io/cran/Ecdat/man/RetSchool.html)\n",
    "- another dataset on schooling and wages\n",
    "- target is log wage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent missing: 0.04%\n",
      "Percent of observations with at least one missing feature: 0.62%\n",
      "Number of unique missing patterns: 1 out of 2,147,483,648 possible patterns.\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "retschool = pd.read_csv('datasets/retschool.csv')\n",
    "\n",
    "# process target\n",
    "retschool.dropna(subset=['wage76'], inplace=True)\n",
    "y = retschool['wage76']\n",
    "\n",
    "# process categorical features\n",
    "drop_cols = ['rownames', 'wage76']\n",
    "retschool = dropColumns(retschool, drop_cols)\n",
    "cat_cols = ['black', 'south76', 'smsa76', 'region', 'smsa66', 'momdad14', 'sinmom14', 'nodaded', 'nomomed', 'famed', 'col4']\n",
    "retschool = cat2Dummies(retschool, cat_cols)\n",
    "\n",
    "# drop non-informative features\n",
    "retschool = dropUninformative(retschool)\n",
    "\n",
    "# append target and save to csv\n",
    "retschool['y'] = y\n",
    "retschool.to_csv('processed_data/retschool.csv', index=False)\n",
    "\n",
    "# print missingness information\n",
    "printMissingness(retschool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UCI REPOSITORY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wiki\n",
    "- source: [UCI dataset repository](https://archive.ics.uci.edu/dataset/334/wiki4he)\n",
    "- survey of Spanish university employees regarding their use and perception of Wikipedia\n",
    "- mix of categorical, continuous and 5-point likert scale variables\n",
    "- the target is a binary *would/would not recommned using Wikipedia to their students*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent missing: 1.52%\n",
      "Percent of observations with at least one missing feature: 31.31%\n",
      "Number of unique missing patterns: 157 out of 147,573,952,589,676,412,928 possible patterns.\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "wiki = pd.read_csv('datasets\\wiki4HE.csv', sep=';')\n",
    "\n",
    "# process categorical features\n",
    "wiki.replace('?', np.nan, inplace=True)\n",
    "cat_cols = ['GENDER', 'DOMAIN', 'PhD', 'UNIVERSITY', 'UOC_POSITION', 'OTHER_POSITION', 'OTHERSTATUS', 'USERWIKI']\n",
    "wiki = cat2Dummies(wiki, cat_cols)\n",
    "wiki = wiki.astype(np.float64)\n",
    "\n",
    "# drop non-informative features\n",
    "wiki = dropUninformative(wiki)\n",
    "\n",
    "# process target (recommends Wiki to students vs. doesn't recommend)\n",
    "wiki.dropna(subset=['Use3'], inplace=True)\n",
    "y = wiki['Use3']\n",
    "y = y.apply(lambda x: 1.0 if x in [5, 4] else 0.0)\n",
    "drop_cols = ['Use1', 'Use2', 'Use3', 'Use4', 'Use5']\n",
    "wiki = dropColumns(wiki, drop_cols)\n",
    "\n",
    "# append target and save to csv\n",
    "wiki['y'] = y\n",
    "wiki.to_csv('processed_data\\yes_miss\\wiki.csv', index=False)\n",
    "\n",
    "# print missingness information\n",
    "printMissingness(wiki)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support2 Dataset\n",
    "- source: [UCI Repository](https://archive.ics.uci.edu/dataset/880/support2)\n",
    "- predict (binary) death from patient information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "Percent missing: 9.30%\n",
      "Percent of observations with at least one missing feature: 96.60%\n",
      "Number of unique missing patterns: 310 out of 1,125,899,906,842,624 possible patterns.\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "support = pd.read_excel('datasets/support.xls', engine='xlrd')\n",
    "\n",
    "# process target\n",
    "y = support['death']\n",
    "y = y.astype(np.float64)\n",
    "\n",
    "# process categorical features\n",
    "support['income'] = support['income'].map({'under $11k': 0, '$11-$25k': 1, '$25-$50k': 2, '>$50k': 3})\n",
    "cat_cols = ['sex', 'dzgroup', 'dzclass', 'race', 'sfdm2']\n",
    "drop_cols = ['hospdead', 'death']\n",
    "support = dropColumns(support, drop_cols)\n",
    "support = cat2Dummies(support, cat_cols)\n",
    "support = support.astype(np.float64)\n",
    "\n",
    "# drop non-informative features\n",
    "support = dropUninformative(support)\n",
    "\n",
    "# append target and save to csv\n",
    "support['y'] = y\n",
    "support.to_csv('processed_data\\yes_miss\\support.csv', index=False)\n",
    "\n",
    "# print missingness information\n",
    "printMissingness(support)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KAGGLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Housing Price dataset\n",
    "- source: [Kaggle](https://www.kaggle.com/competitions/home-data-for-ml-course/data?select=train.csv)\n",
    "- predict sales price based on features of the house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent missing: 0.09%\n",
      "Percent of observations with at least one missing feature: 23.22%\n",
      "Number of unique missing patterns: 5 out of 3,705,346,855,594,118,253,554,271,520,278,013,051,304,639,509,300,498,049,262,642,688,253,220,148,477,952 possible patterns.\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "housing = pd.read_csv('datasets/housing.csv')\n",
    "\n",
    "# process target\n",
    "y = housing['SalePrice']\n",
    "y.astype(np.float64)\n",
    "\n",
    "# process categorical features\n",
    "drop_cols = ['Id', 'SalePrice']\n",
    "housing = dropColumns(housing, drop_cols)\n",
    "cat_cols = housing.select_dtypes(include=['object']).columns\n",
    "housing = cat2Dummies(housing, cat_cols)\n",
    "housing.astype(np.float64)\n",
    "\n",
    "# drop non-informative features\n",
    "housing = dropUninformative(housing)\n",
    "\n",
    "# append target and save to csv\n",
    "housing['y'] = y\n",
    "housing.to_csv('processed_data/housing.csv', index=False)\n",
    "\n",
    "# print missingness information\n",
    "printMissingness(housing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying Age-Related Conditions\n",
    "- source: [Kaggle](https://www.kaggle.com/competitions/icr-identify-age-related-conditions/data?select=train.csv)\n",
    "- predict if patient has been identified with some condition or not (binary classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent missing: 0.37%\n",
      "Percent of observations with at least one missing feature: 11.18%\n",
      "Number of unique missing patterns: 7 out of 144,115,188,075,855,872 possible patterns.\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "icr = pd.read_csv('datasets/icr.csv')\n",
    "\n",
    "# process target\n",
    "y = icr['Class'].astype(np.float64)\n",
    "icr = dropColumns(icr, ['Class'])\n",
    "\n",
    "# process categorical features\n",
    "icr = dropColumns(icr, ['Id'])\n",
    "cat_cols = icr.select_dtypes(include=['object']).columns\n",
    "icr = cat2Dummies(icr, cat_cols)\n",
    "icr = icr.astype(np.float64)\n",
    "\n",
    "# drop non-informative features\n",
    "icr = dropUninformative(icr)\n",
    "\n",
    "# append target and save to csv\n",
    "icr['y'] = y\n",
    "icr.to_csv('processed_data/icr.csv', index=False)\n",
    "\n",
    "# print missingness information\n",
    "printMissingness(icr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPEN-ML DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openml\n",
    "def loadDataset(dataset_id):\n",
    "    dataset = openml.datasets.get_dataset(dataset_id, \n",
    "                                          download_data=True, \n",
    "                                          download_qualities=False, \n",
    "                                          download_features_meta_data=False)\n",
    "    X, y, cat_indicator, feature_names = dataset.get_data(target=dataset.default_target_attribute, \n",
    "                                                          dataset_format='dataframe')\n",
    "    return X, y, cat_indicator, feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothyroid\n",
    "- source: [OpenML id: 1000](https://www.openml.org/search?type=data&status=active&id=1000)\n",
    "- binary classification of thyroid disease "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent missing: 1.77%\n",
      "Percent of observations with at least one missing feature: 27.07%\n",
      "Number of unique missing patterns: 16 out of 4,294,967,296 possible patterns.\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "hypothyroid, y, cat_indicator, feature_names = loadDataset(1000)\n",
    "\n",
    "# process target\n",
    "y = y.apply(lambda x: 1.0 if x == 'P' else 0.0)\n",
    "\n",
    "# process categorical features\n",
    "cat_cols = np.array(feature_names)[np.array(cat_indicator)]\n",
    "hypothyroid = cat2Dummies(hypothyroid, cat_cols)\n",
    "hypothyroid = dropUninformative(hypothyroid)\n",
    "\n",
    "# append target and save to csv\n",
    "hypothyroid['y'] = y\n",
    "hypothyroid.to_csv('processed_data/hypothyroid.csv', index=False)\n",
    "\n",
    "# print missingness information\n",
    "printMissingness(hypothyroid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salaries\n",
    "-  source: [OpenML id: 488](https://www.openml.org/search?type=data&status=active&id=488)\n",
    "- binary prediction of two types of universities based on the salaries of their staff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent missing: 1.57%\n",
      "Percent of observations with at least one missing feature: 7.49%\n",
      "Number of unique missing patterns: 7 out of 16,384 possible patterns.\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "salaries, y, cat_indicator, feature_names = loadDataset(488)\n",
    "\n",
    "# process target\n",
    "y = y.apply(lambda x: 1.0 if x in ['I', 'IIA'] else 0.0)\n",
    "\n",
    "# process categorical features\n",
    "salaries = dropColumns(salaries, ['State'])\n",
    "\n",
    "# append target and save to csv\n",
    "salaries['y'] = y\n",
    "salaries.to_csv('processed_data/salaries.csv', index=False)\n",
    "\n",
    "# print missingness information\n",
    "printMissingness(salaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cirrhosis\n",
    "- source: [OpenML id: 802](https://www.openml.org/search?type=data&status=active&id=802)\n",
    "- predict liver cirrhosis from patient data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent missing: 2.96%\n",
      "Percent of observations with at least one missing feature: 57.02%\n",
      "Number of unique missing patterns: 9 out of 4,194,304 possible patterns.\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "cirrhosis, y, cat_indicator, feature_names = loadDataset(802)\n",
    "\n",
    "# process target\n",
    "y = y.apply(lambda x: 1.0 if x == 'P' else 0.0)\n",
    "\n",
    "# process categorical features\n",
    "cirrhosis['day'] = pd.to_numeric(cirrhosis['day'], errors='coerce')\n",
    "cat_cols = np.array(feature_names)[np.array(cat_indicator)]\n",
    "cat_cols = np.delete(cat_cols, np.where(cat_cols == 'day'))\n",
    "cirrhosis = cat2Dummies(cirrhosis, cat_cols)\n",
    "\n",
    "# drop non-informative features\n",
    "cirrhosis = dropUninformative(cirrhosis)\n",
    "\n",
    "# append target and save to csv\n",
    "cirrhosis['y'] = y\n",
    "cirrhosis.to_csv('processed_data\\yes_miss\\cirrhosis.csv', index=False)\n",
    "\n",
    "# print missingness information\n",
    "printMissingness(cirrhosis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ottawa Real Estate\n",
    "- source: [OpenML id: 43417](https://www.openml.org/search?type=data&status=active&id=43417)\n",
    "- predict price of Ottawa's real estate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent missing: 5.78%\n",
      "Percent of observations with at least one missing feature: 59.53%\n",
      "Number of unique missing patterns: 21 out of 1,073,741,824 possible patterns.\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "ottawa, y, cat_indicator, feature_names = loadDataset(43417)\n",
    "\n",
    "# process target\n",
    "ottawa = ottawa.dropna(subset=['price'])\n",
    "y = pd.to_numeric(ottawa.price.str.replace(',', ''), errors='coerce')\n",
    "y = y.astype(float)\n",
    "\n",
    "# process categorical features\n",
    "drop_cols = ['price']\n",
    "ottawa = dropColumns(ottawa, ['price'])\n",
    "cat_cols = ['propertyType', 'style']\n",
    "ottawa = cat2Dummies(ottawa, cat_cols)\n",
    "\n",
    "# drop non-informative features\n",
    "ottawa = dropUninformative(ottawa)\n",
    "\n",
    "# append target and save to csv\n",
    "ottawa['y'] = y\n",
    "ottawa.to_csv('processed_data/ottawa.csv', index=False)\n",
    "\n",
    "# print missingness information\n",
    "printMissingness(ottawa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polish Bankruptcy\n",
    "- source: [OpenML id: 42987](https://www.openml.org/search?type=data&status=active&id=42987)\n",
    "- predict bankruptcy of Polish firms from numerical variables only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent missing: 1.21%\n",
      "Percent of observations with at least one missing feature: 48.71%\n",
      "Number of unique missing patterns: 83 out of 36,893,488,147,419,103,232 possible patterns.\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "bankruptcy, y, cat_indicator, feature_names = loadDataset(42987)\n",
    "\n",
    "# process target\n",
    "y = bankruptcy['class']\n",
    "y = y.astype(np.float64)\n",
    "bankruptcy = dropColumns(bankruptcy, ['class'])\n",
    "\n",
    "# append target and save to csv\n",
    "bankruptcy['y'] = y\n",
    "bankruptcy.to_csv('processed_data/bankruptcy.csv', index=False)\n",
    "\n",
    "# print missingness information\n",
    "printMissingness(bankruptcy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Home Equity Default\n",
    "- source: [OpenML id: 43337](https://www.openml.org/search?type=data&status=active&id=43337)\n",
    "- binary prediction of defaulting on home equity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent missing: 4.19%\n",
      "Percent of observations with at least one missing feature: 41.02%\n",
      "Number of unique missing patterns: 74 out of 524,288 possible patterns.\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "equity, y, cat_indicator, feature_names = loadDataset(43337)\n",
    "\n",
    "# process target\n",
    "y = equity.BAD.astype(np.float64)\n",
    "\n",
    "# process categorical features\n",
    "equity = dropColumns(equity, ['BAD'])\n",
    "cat_cols = ['REASON', 'JOB']\n",
    "equity = cat2Dummies(equity, cat_cols)\n",
    "equity = equity.astype(np.float64)\n",
    "\n",
    "# drop non-informative features\n",
    "equity = dropUninformative(equity)\n",
    "\n",
    "# append target and save to csv\n",
    "equity['y'] = y\n",
    "equity.to_csv('processed_data\\yes_miss\\equity.csv', index=False)\n",
    "\n",
    "# print missingness information\n",
    "printMissingness(equity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fico Credit Scoring\n",
    "- source: [Open ML id: 45554](https://www.openml.org/search?type=data&status=active&id=45554&sort=runs)\n",
    "- predict GOOD/BAD credit score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent missing: 3.37%\n",
      "Percent of observations with at least one missing feature: 74.65%\n",
      "Number of unique missing patterns: 74 out of 274,877,906,944 possible patterns.\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "fico, y, cat_indicator, feature_names = loadDataset(45554)\n",
    "\n",
    "# process target\n",
    "y = y.apply(lambda x: 1.0 if x == 'Good' else 0.0)\n",
    "\n",
    "# process categorical features\n",
    "cat_cols = np.array(feature_names)[np.array(cat_indicator)]\n",
    "fico = cat2Dummies(fico, cat_cols)\n",
    "fico = fico.astype(np.float64)\n",
    "\n",
    "# drop non-informative features\n",
    "fico = dropUninformative(fico)\n",
    "\n",
    "# append target and save to csv\n",
    "fico['y'] = y\n",
    "fico.to_csv('processed_data/yes_miss/fico.csv', index=False)\n",
    "\n",
    "# print missingness information\n",
    "printMissingness(fico)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mice Protein Expression\n",
    "- course: [OpenML id: 43445](https://www.openml.org/search?type=data&status=active&id=43445)\n",
    "- expression of 77 proteins in mice' cerebral cortex used for binary prediction of control vs. treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent missing: 1.66%\n",
      "Percent of observations with at least one missing feature: 48.89%\n",
      "Number of unique missing patterns: 26 out of 302,231,454,903,657,293,676,544 possible patterns.\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "mice, y, cat_indicator, feature_names = loadDataset(43445)\n",
    "\n",
    "# process target\n",
    "y = mice['class']\n",
    "y = y.apply(lambda x: 1.0 if x[2:4] == 'CS' else 0.0)\n",
    "\n",
    "# process categorical features\n",
    "mice = dropColumns(mice, ['Genotype', 'Treatment', 'Behavior', 'class'])\n",
    "\n",
    "# append target and save to csv\n",
    "mice['y'] = y\n",
    "mice.to_csv('processed_data/mice.csv', index=False)\n",
    "\n",
    "# print missingness information\n",
    "printMissingness(mice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "directory = 'processed_data/yes_miss'\n",
    "datasets = os.listdir(directory)\n",
    "columns=['dataset', 'n', 'd', 'd/n', 'frac_missing', 'frac_n_with_missing', 'missing_patterns', 'frac_missing_patterns']\n",
    "descriptive_stats = []\n",
    "\n",
    "for dataset in datasets:\n",
    "    df = pd.read_csv(f'{directory}/{dataset}')\n",
    "    n, d = df.shape\n",
    "    d_miss = df.isna().sum().sum()/df.size\n",
    "    d_obs_miss = df.isna().any(axis=1).sum()/n\n",
    "    miss_patterns = getNumMissingPatterns(df)\n",
    "    frac_miss_patterns = miss_patterns/(2**d)\n",
    "    descriptive_stats.append([dataset[:-4], n, d, d/n, d_miss, d_obs_miss, miss_patterns, frac_miss_patterns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>n</th>\n",
       "      <th>d</th>\n",
       "      <th>d/n</th>\n",
       "      <th>frac_missing</th>\n",
       "      <th>frac_n_with_missing</th>\n",
       "      <th>missing_patterns</th>\n",
       "      <th>frac_missing_patterns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>support</td>\n",
       "      <td>1000</td>\n",
       "      <td>50</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.093000</td>\n",
       "      <td>0.966000</td>\n",
       "      <td>310</td>\n",
       "      <td>2.753353e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>equity</td>\n",
       "      <td>5960</td>\n",
       "      <td>19</td>\n",
       "      <td>0.003188</td>\n",
       "      <td>0.041858</td>\n",
       "      <td>0.410235</td>\n",
       "      <td>74</td>\n",
       "      <td>1.411438e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fico</td>\n",
       "      <td>9871</td>\n",
       "      <td>38</td>\n",
       "      <td>0.003850</td>\n",
       "      <td>0.033706</td>\n",
       "      <td>0.746530</td>\n",
       "      <td>74</td>\n",
       "      <td>2.692104e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cirrhosis</td>\n",
       "      <td>1945</td>\n",
       "      <td>22</td>\n",
       "      <td>0.011311</td>\n",
       "      <td>0.029586</td>\n",
       "      <td>0.570180</td>\n",
       "      <td>9</td>\n",
       "      <td>2.145767e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wiki</td>\n",
       "      <td>904</td>\n",
       "      <td>67</td>\n",
       "      <td>0.074115</td>\n",
       "      <td>0.015157</td>\n",
       "      <td>0.313053</td>\n",
       "      <td>157</td>\n",
       "      <td>1.063873e-18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     dataset     n   d       d/n  frac_missing  frac_n_with_missing  \\\n",
       "3    support  1000  50  0.050000      0.093000             0.966000   \n",
       "1     equity  5960  19  0.003188      0.041858             0.410235   \n",
       "2       fico  9871  38  0.003850      0.033706             0.746530   \n",
       "0  cirrhosis  1945  22  0.011311      0.029586             0.570180   \n",
       "4       wiki   904  67  0.074115      0.015157             0.313053   \n",
       "\n",
       "   missing_patterns  frac_missing_patterns  \n",
       "3               310           2.753353e-13  \n",
       "1                74           1.411438e-04  \n",
       "2                74           2.692104e-10  \n",
       "0                 9           2.145767e-06  \n",
       "4               157           1.063873e-18  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptive_stats = pd.DataFrame(descriptive_stats, columns=columns).sort_values(by='d/n', ascending=False)\n",
    "descriptive_stats = descriptive_stats.sort_values(by='frac_missing', ascending=False)\n",
    "descriptive_stats.to_csv('results\\csvs\\descriptive_statistics_yes_miss_datasets.csv', index=False)\n",
    "descriptive_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data W/O Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "openML_ids = {'philippine': 41145, \n",
    "              'christine': 41142, \n",
    "              'phoneme': 1489, \n",
    "              'wine_quality': 287, \n",
    "              'airfoil': 43919}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Philippine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "X, y, cat_indicator, feature_names = loadDataset(openML_ids['philippine'])\n",
    "\n",
    "# process target\n",
    "y = y.astype(np.float64)\n",
    "\n",
    "# MCAR: 33% of instances have 33% missing features\n",
    "np.random.seed(101010)\n",
    "n, p = X.shape\n",
    "X_missing_MCAR = X.copy()\n",
    "miss_instances = np.random.choice(X.index, size=int(0.33*n), replace=False)\n",
    "for instance in miss_instances:\n",
    "    miss_features = np.random.choice(X.columns, size=int(0.33*p), replace=False)\n",
    "    X_missing_MCAR.loc[instance, miss_features] = np.nan\n",
    "\n",
    "# MNAR: 20% of features have upper and lower quartile missing\n",
    "np.random.seed(101010)\n",
    "n, p = X.shape\n",
    "X_missing_MNAR = X.copy()\n",
    "miss_features = np.random.choice(X.columns, size=int(0.2*p), replace=False)\n",
    "for feature in miss_features:\n",
    "    lower, upper = X[feature].quantile([0.25, 0.75])\n",
    "    miss_instances = X.loc[(X[feature] < lower) | (X[feature] > upper)].index\n",
    "    X_missing_MNAR.loc[miss_instances, feature] = np.nan\n",
    "\n",
    "# combine features and target\n",
    "X['y'] = y\n",
    "X_missing_MCAR['y'] = y\n",
    "X_missing_MNAR['y'] = y\n",
    "\n",
    "# save to csv\n",
    "X.to_csv('processed_data/no_miss/philippine.csv', index=False)\n",
    "X_missing_MCAR.to_csv('processed_data/no_miss/philippine_MCAR.csv', index=False)\n",
    "X_missing_MNAR.to_csv('processed_data/no_miss/philippine_MNAR.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Christine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent missing: 9.26%\n",
      "Percent of observations with at least one missing feature: 100.00%\n",
      "Number of unique missing patterns: 5418 out of 6,110,867,989,448,014,552,298,782,828,208,316,193,809,952,885,676,369,117,472,133,309,891,328,341,254,636,644,354,714,157,002,810,478,547,402,909,205,659,254,601,798,041,839,816,652,081,811,650,677,690,905,917,381,732,887,612,552,813,375,176,895,148,575,684,957,849,535,635,099,785,528,429,764,712,843,434,636,874,594,921,661,022,703,043,781,268,266,332,365,112,500,876,034,108,471,429,975,847,694,022,676,972,136,745,059,017,077,493,834,603,591,563,046,655,596,486,594,803,473,706,869,542,019,927,630,658,780,868,329,467,859,090,412,022,547,341,819,128,775,067,876,977,713,139,580,394,765,119,898,285,824,332,940,707,170,586,319,251,168,872,337,843,945,472 possible patterns.\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "X, y, cat_indicator, feature_names = loadDataset(openML_ids['christine'])\n",
    "\n",
    "# process target\n",
    "y = y.astype(np.float64)\n",
    "\n",
    "# MCAR: 33% of instances have 33% missing numerical features\n",
    "np.random.seed(101010)\n",
    "n, p = X.shape\n",
    "X_missing_MCAR = X.copy()\n",
    "miss_instances = np.random.choice(X.index, size=int(0.33*n), replace=False)\n",
    "for instance in miss_instances:\n",
    "    miss_features = np.random.choice(X.columns[~np.array(cat_indicator)], size=int(0.33*p), replace=False)\n",
    "    X_missing_MCAR.loc[instance, miss_features] = np.nan\n",
    "\n",
    "# MNAR: 20% of numeric features have upper and lower quartile missing\n",
    "np.random.seed(101010)\n",
    "n, p = X.shape\n",
    "X_missing_MNAR = X.copy()\n",
    "miss_features = X.columns[~np.array(cat_indicator)]\n",
    "miss_features = np.random.choice(miss_features, size=int(0.2*p), replace=False)\n",
    "for feature in miss_features:\n",
    "    lower, upper = X[feature].quantile([0.25, 0.75])\n",
    "    miss_instances = X.loc[(X[feature] < lower) | (X[feature] > upper)].index\n",
    "    X_missing_MNAR.loc[miss_instances, feature] = np.nan        \n",
    "\n",
    "# combine features and target\n",
    "X['y'] = y\n",
    "X_missing_MCAR['y'] = y\n",
    "X_missing_MNAR['y'] = y\n",
    "\n",
    "# save to csv\n",
    "X.to_csv('processed_data/no_miss/christine.csv', index=False)\n",
    "X_missing_MCAR.to_csv('processed_data/no_miss/christine_MCAR.csv', index=False)\n",
    "X_missing_MNAR.to_csv('processed_data/no_miss/christine_MNAR.csv', index=False)\n",
    "\n",
    "\n",
    "printMissingness(X_missing_MNAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phoneme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "X, y, cat_indicator, feature_names = loadDataset(openML_ids['phoneme'])\n",
    "\n",
    "# process target\n",
    "y = y.map(lambda x: 1.0 if x == '1' else 0.0)\n",
    "y = y.astype(np.float64)\n",
    "\n",
    "# MCAR: 33% of instances have 33% missing features\n",
    "np.random.seed(101010)\n",
    "n, p = X.shape\n",
    "X_missing_MCAR = X.copy()\n",
    "miss_instances = np.random.choice(X.index, size=int(0.33*n), replace=False)\n",
    "for instance in miss_instances:\n",
    "    miss_features = np.random.choice(X.columns, size=int(0.33*p), replace=False)\n",
    "    X_missing_MCAR.loc[instance, miss_features] = np.nan\n",
    "\n",
    "# MNAR: 20% of features have upper and lower quartile missing\n",
    "np.random.seed(101010)\n",
    "n, p = X.shape\n",
    "X_missing_MNAR = X.copy()\n",
    "miss_features = np.random.choice(X.columns, size=int(0.2*p), replace=False)\n",
    "for feature in miss_features:\n",
    "    lower, upper = X[feature].quantile([0.25, 0.75])\n",
    "    miss_instances = X.loc[(X[feature] < lower) | (X[feature] > upper)].index\n",
    "    X_missing_MNAR.loc[miss_instances, feature] = np.nan\n",
    "\n",
    "# combine features and target\n",
    "X['y'] = y\n",
    "X_missing_MCAR['y'] = y\n",
    "X_missing_MNAR['y'] = y\n",
    "\n",
    "# save to csv\n",
    "X.to_csv('processed_data/no_miss/phoneme.csv', index=False)\n",
    "X_missing_MCAR.to_csv('processed_data/no_miss/phoneme_MCAR.csv', index=False)\n",
    "X_missing_MNAR.to_csv('processed_data/no_miss/phoneme_MNAR.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wine_quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "X, y, cat_indicator, feature_names = loadDataset(openML_ids['wine_quality'])\n",
    "\n",
    "# process target\n",
    "y = y.astype(np.float64)\n",
    "\n",
    "# MCAR: 33% of instances have 33% missing features\n",
    "np.random.seed(101010)\n",
    "n, p = X.shape\n",
    "X_missing_MCAR = X.copy()\n",
    "miss_instances = np.random.choice(X.index, size=int(0.33*n), replace=False)\n",
    "for instance in miss_instances:\n",
    "    miss_features = np.random.choice(X.columns, size=int(0.33*p), replace=False)\n",
    "    X_missing_MCAR.loc[instance, miss_features] = np.nan\n",
    "\n",
    "# MNAR: 20% of features have upper and lower quartile missing\n",
    "np.random.seed(101010)\n",
    "n, p = X.shape\n",
    "X_missing_MNAR = X.copy()\n",
    "miss_features = np.random.choice(X.columns, size=int(0.2*p), replace=False)\n",
    "for feature in miss_features:\n",
    "    lower, upper = X[feature].quantile([0.25, 0.75])\n",
    "    miss_instances = X.loc[(X[feature] < lower) | (X[feature] > upper)].index\n",
    "    X_missing_MNAR.loc[miss_instances, feature] = np.nan\n",
    "\n",
    "# combine features and target\n",
    "X['y'] = y\n",
    "X_missing_MCAR['y'] = y\n",
    "X_missing_MNAR['y'] = y\n",
    "\n",
    "# save to csv\n",
    "X.to_csv('processed_data/no_miss/wine_quality.csv', index=False)\n",
    "X_missing_MCAR.to_csv('processed_data/no_miss/wine_quality_MCAR.csv', index=False)\n",
    "X_missing_MNAR.to_csv('processed_data/no_miss/wine_quality_MNAR.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### airfoil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "X, y, cat_indicator, feature_names = loadDataset(openML_ids['airfoil'])\n",
    "\n",
    "# process target\n",
    "y\n",
    "\n",
    "# MCAR: 33% of instances have 33% missing features\n",
    "np.random.seed(101010)\n",
    "n, p = X.shape\n",
    "X_missing_MCAR = X.copy()\n",
    "miss_instances = np.random.choice(X.index, size=int(0.33*n), replace=False)\n",
    "for instance in miss_instances:\n",
    "    miss_features = np.random.choice(X.columns, size=int(0.33*p), replace=False)\n",
    "    X_missing_MCAR.loc[instance, miss_features] = np.nan\n",
    "\n",
    "# MNAR: 20% of features have upper and lower quartile missing\n",
    "np.random.seed(101010)\n",
    "n, p = X.shape\n",
    "X_missing_MNAR = X.copy()\n",
    "miss_features = np.random.choice(X.columns, size=int(0.2*p), replace=False)\n",
    "for feature in miss_features:\n",
    "    lower, upper = X[feature].quantile([0.25, 0.75])\n",
    "    miss_instances = X.loc[(X[feature] < lower) | (X[feature] > upper)].index\n",
    "    X_missing_MNAR.loc[miss_instances, feature] = np.nan\n",
    "\n",
    "# combine features and target\n",
    "X['y'] = y\n",
    "X_missing_MCAR['y'] = y\n",
    "X_missing_MNAR['y'] = y\n",
    "\n",
    "# save to csv\n",
    "X.to_csv('processed_data/no_miss/airfoil.csv', index=False)\n",
    "X_missing_MCAR.to_csv('processed_data/no_miss/airfoil_MCAR.csv', index=False)\n",
    "X_missing_MNAR.to_csv('processed_data/no_miss/airfoil_MNAR.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "directory = 'processed_data/no_miss'\n",
    "datasets = os.listdir(directory)\n",
    "columns=['dataset', 'n', 'd', 'd/n', 'frac_missing', 'frac_n_with_missing', 'missing_patterns', 'frac_missing_patterns', 'type_of_missingness']\n",
    "descriptive_stats = []\n",
    "\n",
    "for dataset in datasets:\n",
    "    df = pd.read_csv(f'{directory}/{dataset}')\n",
    "    n, d = df.shape\n",
    "    d_miss = df.isna().sum().sum()/df.size\n",
    "    d_obs_miss = df.isna().any(axis=1).sum()/n\n",
    "    miss_patterns = getNumMissingPatterns(df)\n",
    "    frac_miss_patterns = miss_patterns/(2**d)\n",
    "    miss_type = 'MCAR' if 'MCAR' in dataset else 'MNAR' if 'MNAR' in dataset else 'none'\n",
    "    descriptive_stats.append([dataset[:-4], n, d, d/n, d_miss, d_obs_miss, miss_patterns, frac_miss_patterns, miss_type])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>n</th>\n",
       "      <th>d</th>\n",
       "      <th>d/n</th>\n",
       "      <th>frac_missing</th>\n",
       "      <th>frac_n_with_missing</th>\n",
       "      <th>missing_patterns</th>\n",
       "      <th>frac_missing_patterns</th>\n",
       "      <th>type_of_missingness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>christine_MCAR</td>\n",
       "      <td>5418</td>\n",
       "      <td>1637</td>\n",
       "      <td>0.302141</td>\n",
       "      <td>0.108599</td>\n",
       "      <td>0.329827</td>\n",
       "      <td>1787</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>MCAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>philippine_MCAR</td>\n",
       "      <td>5832</td>\n",
       "      <td>309</td>\n",
       "      <td>0.052984</td>\n",
       "      <td>0.107833</td>\n",
       "      <td>0.329904</td>\n",
       "      <td>1924</td>\n",
       "      <td>1.844745e-90</td>\n",
       "      <td>MCAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>airfoil_MCAR</td>\n",
       "      <td>1503</td>\n",
       "      <td>6</td>\n",
       "      <td>0.003992</td>\n",
       "      <td>0.054890</td>\n",
       "      <td>0.329341</td>\n",
       "      <td>5</td>\n",
       "      <td>7.812500e-02</td>\n",
       "      <td>MCAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>wine_quality_MCAR</td>\n",
       "      <td>6497</td>\n",
       "      <td>12</td>\n",
       "      <td>0.001847</td>\n",
       "      <td>0.082500</td>\n",
       "      <td>0.329998</td>\n",
       "      <td>165</td>\n",
       "      <td>4.028320e-02</td>\n",
       "      <td>MCAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>phoneme_MCAR</td>\n",
       "      <td>5404</td>\n",
       "      <td>6</td>\n",
       "      <td>0.001110</td>\n",
       "      <td>0.054990</td>\n",
       "      <td>0.329941</td>\n",
       "      <td>5</td>\n",
       "      <td>7.812500e-02</td>\n",
       "      <td>MCAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>christine_MNAR</td>\n",
       "      <td>5418</td>\n",
       "      <td>1637</td>\n",
       "      <td>0.302141</td>\n",
       "      <td>0.092605</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5418</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>MNAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>philippine_MNAR</td>\n",
       "      <td>5832</td>\n",
       "      <td>309</td>\n",
       "      <td>0.052984</td>\n",
       "      <td>0.097573</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5832</td>\n",
       "      <td>5.591764e-90</td>\n",
       "      <td>MNAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>airfoil_MNAR</td>\n",
       "      <td>1503</td>\n",
       "      <td>6</td>\n",
       "      <td>0.003992</td>\n",
       "      <td>0.082834</td>\n",
       "      <td>0.497006</td>\n",
       "      <td>1</td>\n",
       "      <td>1.562500e-02</td>\n",
       "      <td>MNAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>wine_quality_MNAR</td>\n",
       "      <td>6497</td>\n",
       "      <td>12</td>\n",
       "      <td>0.001847</td>\n",
       "      <td>0.080101</td>\n",
       "      <td>0.725258</td>\n",
       "      <td>3</td>\n",
       "      <td>7.324219e-04</td>\n",
       "      <td>MNAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>phoneme_MNAR</td>\n",
       "      <td>5404</td>\n",
       "      <td>6</td>\n",
       "      <td>0.001110</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.562500e-02</td>\n",
       "      <td>MNAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>christine</td>\n",
       "      <td>5418</td>\n",
       "      <td>1637</td>\n",
       "      <td>0.302141</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>philippine</td>\n",
       "      <td>5832</td>\n",
       "      <td>309</td>\n",
       "      <td>0.052984</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>airfoil</td>\n",
       "      <td>1503</td>\n",
       "      <td>6</td>\n",
       "      <td>0.003992</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>wine_quality</td>\n",
       "      <td>6497</td>\n",
       "      <td>12</td>\n",
       "      <td>0.001847</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>phoneme</td>\n",
       "      <td>5404</td>\n",
       "      <td>6</td>\n",
       "      <td>0.001110</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              dataset     n     d       d/n  frac_missing  \\\n",
       "4      christine_MCAR  5418  1637  0.302141      0.108599   \n",
       "7     philippine_MCAR  5832   309  0.052984      0.107833   \n",
       "1        airfoil_MCAR  1503     6  0.003992      0.054890   \n",
       "13  wine_quality_MCAR  6497    12  0.001847      0.082500   \n",
       "10       phoneme_MCAR  5404     6  0.001110      0.054990   \n",
       "5      christine_MNAR  5418  1637  0.302141      0.092605   \n",
       "8     philippine_MNAR  5832   309  0.052984      0.097573   \n",
       "2        airfoil_MNAR  1503     6  0.003992      0.082834   \n",
       "14  wine_quality_MNAR  6497    12  0.001847      0.080101   \n",
       "11       phoneme_MNAR  5404     6  0.001110      0.083333   \n",
       "3           christine  5418  1637  0.302141      0.000000   \n",
       "6          philippine  5832   309  0.052984      0.000000   \n",
       "0             airfoil  1503     6  0.003992      0.000000   \n",
       "12       wine_quality  6497    12  0.001847      0.000000   \n",
       "9             phoneme  5404     6  0.001110      0.000000   \n",
       "\n",
       "    frac_n_with_missing  missing_patterns  frac_missing_patterns  \\\n",
       "4              0.329827              1787           0.000000e+00   \n",
       "7              0.329904              1924           1.844745e-90   \n",
       "1              0.329341                 5           7.812500e-02   \n",
       "13             0.329998               165           4.028320e-02   \n",
       "10             0.329941                 5           7.812500e-02   \n",
       "5              1.000000              5418           0.000000e+00   \n",
       "8              1.000000              5832           5.591764e-90   \n",
       "2              0.497006                 1           1.562500e-02   \n",
       "14             0.725258                 3           7.324219e-04   \n",
       "11             0.500000                 1           1.562500e-02   \n",
       "3              0.000000                 0           0.000000e+00   \n",
       "6              0.000000                 0           0.000000e+00   \n",
       "0              0.000000                 0           0.000000e+00   \n",
       "12             0.000000                 0           0.000000e+00   \n",
       "9              0.000000                 0           0.000000e+00   \n",
       "\n",
       "   type_of_missingness  \n",
       "4                 MCAR  \n",
       "7                 MCAR  \n",
       "1                 MCAR  \n",
       "13                MCAR  \n",
       "10                MCAR  \n",
       "5                 MNAR  \n",
       "8                 MNAR  \n",
       "2                 MNAR  \n",
       "14                MNAR  \n",
       "11                MNAR  \n",
       "3                 none  \n",
       "6                 none  \n",
       "0                 none  \n",
       "12                none  \n",
       "9                 none  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptive_stats = pd.DataFrame(descriptive_stats, columns=columns).sort_values(by='d/n', ascending=False)\n",
    "descriptive_stats = descriptive_stats.sort_values(by='type_of_missingness', ascending=True)\n",
    "descriptive_stats.to_csv('results\\csvs\\descriptive_statistics_no_miss_datasets.csv', index=False)\n",
    "\n",
    "descriptive_stats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
